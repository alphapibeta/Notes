Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 1 1 1024 1024 gpu
CLI arguments: block_x = 1, block_y = 1, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 6587 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 2.09846 seconds.
==PROF== Disconnected from process 6587
[6587] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (1024, 1024, 1)x(1, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- --------------
    Metric Name               Metric Unit   Metric Value
    ----------------------- ------------- --------------
    DRAM Frequency          cycle/nsecond           6.80
    SM Frequency            cycle/usecond         960.53
    Elapsed Cycles                  cycle    174,579,828
    Memory Throughput                   %          82.13
    DRAM Throughput                     %           7.26
    Duration                      msecond         181.75
    L1/TEX Cache Throughput             %          82.13
    L2 Cache Throughput                 %          22.98
    SM Active Cycles                cycle 174,602,093.63
    Compute (SM) Throughput             %          82.13
    ----------------------- ------------- --------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     1
    Function Cache Configuration                     CachePreferNone
    Grid Size                                              1,048,576
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                            2,184.53
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 96.88%                                                                                          
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 1      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           36
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.88
    Achieved Active Warps Per SM           warp        15.96
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 1 2 1024 1024 gpu
CLI arguments: block_x = 1, block_y = 2, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 6639 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 1.39014 seconds.
==PROF== Disconnected from process 6639
[6639] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (1024, 512, 1)x(1, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- --------------
    Metric Name               Metric Unit   Metric Value
    ----------------------- ------------- --------------
    DRAM Frequency          cycle/nsecond           6.80
    SM Frequency            cycle/usecond         960.34
    Elapsed Cycles                  cycle    110,572,668
    Memory Throughput                   %          64.83
    DRAM Throughput                     %           5.74
    Duration                      msecond         115.14
    L1/TEX Cache Throughput             %          97.24
    L2 Cache Throughput                 %          18.29
    SM Active Cycles                cycle 110,578,249.47
    Compute (SM) Throughput             %          64.83
    ----------------------- ------------- --------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     2
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                524,288
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                            1,092.27
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 93.75%                                                                                          
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 2      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           36
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.90
    Achieved Active Warps Per SM           warp        15.97
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 1 4 1024 1024 gpu
CLI arguments: block_x = 1, block_y = 4, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 6685 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 1.20597 seconds.
==PROF== Disconnected from process 6685
[6685] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (1024, 256, 1)x(1, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.79
    SM Frequency            cycle/usecond        960.07
    Elapsed Cycles                  cycle    89,671,603
    Memory Throughput                   %         49.95
    DRAM Throughput                     %          3.55
    Duration                      msecond         93.40
    L1/TEX Cache Throughput             %         99.90
    L2 Cache Throughput                 %         12.32
    SM Active Cycles                cycle 89,660,373.17
    Compute (SM) Throughput             %         39.97
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     4
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                262,144
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                              546.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 87.5%                                                                                           
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           36
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.92
    Achieved Active Warps Per SM           warp        15.97
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 1 8 1024 1024 gpu
CLI arguments: block_x = 1, block_y = 8, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 6739 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 1.17905 seconds.
==PROF== Disconnected from process 6739
[6739] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (1024, 128, 1)x(1, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.79
    SM Frequency            cycle/usecond        959.99
    Elapsed Cycles                  cycle    80,749,914
    Memory Throughput                   %         49.93
    DRAM Throughput                     %          1.99
    Duration                      msecond         84.11
    L1/TEX Cache Throughput             %         99.86
    L2 Cache Throughput                 %          5.02
    SM Active Cycles                cycle 80,707,828.17
    Compute (SM) Throughput             %         22.19
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                131,072
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                              273.07
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 75%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           36
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.92
    Achieved Active Warps Per SM           warp        15.97
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 1 16 1024 1024 gpu
CLI arguments: block_x = 1, block_y = 16, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 6802 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 1.09617 seconds.
==PROF== Disconnected from process 6802
[6802] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (1024, 64, 1)x(1, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.79
    SM Frequency            cycle/usecond        959.84
    Elapsed Cycles                  cycle    76,232,839
    Memory Throughput                   %         49.94
    DRAM Throughput                     %          1.07
    Duration                      msecond         79.42
    L1/TEX Cache Throughput             %         99.89
    L2 Cache Throughput                 %          3.76
    SM Active Cycles                cycle 76,172,870.77
    Compute (SM) Throughput             %         11.75
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 65,536
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                              136.53
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           36
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.87
    Achieved Active Warps Per SM           warp        15.96
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 1 32 1024 1024 gpu
CLI arguments: block_x = 1, block_y = 32, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 6872 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 1.10599 seconds.
==PROF== Disconnected from process 6872
[6872] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (1024, 32, 1)x(1, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.80
    SM Frequency            cycle/usecond        960.44
    Elapsed Cycles                  cycle    74,041,298
    Memory Throughput                   %         49.90
    DRAM Throughput                     %          0.57
    Duration                      msecond         77.09
    L1/TEX Cache Throughput             %         99.81
    L2 Cache Throughput                 %          3.13
    SM Active Cycles                cycle 73,896,991.33
    Compute (SM) Throughput             %          6.05
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 32,768
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               68.27
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           36
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.76
    Achieved Active Warps Per SM           warp        15.92
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 1 64 1024 1024 gpu
CLI arguments: block_x = 1, block_y = 64, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 6937 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 1.08495 seconds.
==PROF== Disconnected from process 6937
[6937] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (1024, 16, 1)x(1, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.79
    SM Frequency            cycle/usecond        959.85
    Elapsed Cycles                  cycle    74,157,928
    Memory Throughput                   %         49.84
    DRAM Throughput                     %          0.30
    Duration                      msecond         77.26
    L1/TEX Cache Throughput             %         99.67
    L2 Cache Throughput                 %          6.26
    SM Active Cycles                cycle 74,000,438.17
    Compute (SM) Throughput             %          6.04
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 16,384
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           18
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        97.38
    Achieved Active Warps Per SM           warp        31.16
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 1 128 1024 1024 gpu
CLI arguments: block_x = 1, block_y = 128, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 7020 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 1.07462 seconds.
==PROF== Disconnected from process 7020
[7020] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (1024, 8, 1)x(1, 128, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.80
    SM Frequency            cycle/usecond        960.46
    Elapsed Cycles                  cycle    74,489,537
    Memory Throughput                   %         49.62
    DRAM Throughput                     %          0.17
    Duration                      msecond         77.55
    L1/TEX Cache Throughput             %         99.24
    L2 Cache Throughput                 %         13.16
    SM Active Cycles                cycle 74,327,068.27
    Compute (SM) Throughput             %          6.02
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  8,192
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            9
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.79
    Achieved Active Warps Per SM           warp        31.61
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 1 256 1024 1024 gpu
CLI arguments: block_x = 1, block_y = 256, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 7083 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 1.07615 seconds.
==PROF== Disconnected from process 7083
[7083] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (1024, 4, 1)x(1, 256, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.80
    SM Frequency            cycle/usecond        960.08
    Elapsed Cycles                  cycle    74,519,377
    Memory Throughput                   %         49.60
    DRAM Throughput                     %          0.10
    Duration                      msecond         77.61
    L1/TEX Cache Throughput             %         99.20
    L2 Cache Throughput                 %         13.95
    SM Active Cycles                cycle 74,176,327.77
    Compute (SM) Throughput             %          6.01
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  4,096
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.71
    Achieved Active Warps Per SM           warp        31.59
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 1 512 1024 1024 gpu
CLI arguments: block_x = 1, block_y = 512, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 7137 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 1.08477 seconds.
==PROF== Disconnected from process 7137
[7137] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (1024, 2, 1)x(1, 512, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.79
    SM Frequency            cycle/usecond        959.84
    Elapsed Cycles                  cycle    74,548,399
    Memory Throughput                   %         49.63
    DRAM Throughput                     %          0.08
    Duration                      msecond         77.66
    L1/TEX Cache Throughput             %         99.27
    L2 Cache Throughput                 %         20.59
    SM Active Cycles                cycle 74,123,611.20
    Compute (SM) Throughput             %          6.01
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  2,048
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.82
    Achieved Active Warps Per SM           warp        31.62
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 1 1024 1024 1024 gpu
CLI arguments: block_x = 1, block_y = 1024, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 7207 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 1.0857 seconds.
==PROF== Disconnected from process 7207
[7207] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (1024, 1, 1)x(1, 1024, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.79
    SM Frequency            cycle/usecond        959.20
    Elapsed Cycles                  cycle    75,427,105
    Memory Throughput                   %         56.66
    DRAM Throughput                     %          0.62
    Duration                      msecond         78.58
    L1/TEX Cache Throughput             %         98.55
    L2 Cache Throughput                 %         56.66
    SM Active Cycles                cycle 74,276,466.23
    Compute (SM) Throughput             %          5.94
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,024
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            1
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.43
    Achieved Active Warps Per SM           warp        31.50
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 2 1 1024 1024 gpu
CLI arguments: block_x = 2, block_y = 1, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 7280 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 1.24708 seconds.
==PROF== Disconnected from process 7280
[7280] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (512, 1024, 1)x(2, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.80
    SM Frequency            cycle/usecond        959.17
    Elapsed Cycles                  cycle    88,308,819
    Memory Throughput                   %         81.29
    DRAM Throughput                     %         14.35
    Duration                      msecond         91.95
    L1/TEX Cache Throughput             %         81.29
    L2 Cache Throughput                 %         26.19
    SM Active Cycles                cycle 88,200,733.07
    Compute (SM) Throughput             %         81.29
    ----------------------- ------------- -------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     2
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                524,288
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                            1,092.27
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 93.75%                                                                                          
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 2      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           36
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.88
    Achieved Active Warps Per SM           warp        15.96
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 2 2 1024 1024 gpu
CLI arguments: block_x = 2, block_y = 2, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 7346 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.942387 seconds.
==PROF== Disconnected from process 7346
[7346] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (512, 512, 1)x(2, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.79
    SM Frequency            cycle/usecond        959.49
    Elapsed Cycles                  cycle    55,077,514
    Memory Throughput                   %         65.12
    DRAM Throughput                     %         11.52
    Duration                      msecond         57.37
    L1/TEX Cache Throughput             %         97.67
    L2 Cache Throughput                 %         21.30
    SM Active Cycles                cycle 55,068,056.93
    Compute (SM) Throughput             %         65.12
    ----------------------- ------------- -------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     4
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                262,144
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                              546.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 87.5%                                                                                           
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           36
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.89
    Achieved Active Warps Per SM           warp        15.96
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 2 4 1024 1024 gpu
CLI arguments: block_x = 2, block_y = 4, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 7397 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.819796 seconds.
==PROF== Disconnected from process 7397
[7397] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (512, 256, 1)x(2, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.79
    SM Frequency            cycle/usecond        959.71
    Elapsed Cycles                  cycle    44,841,623
    Memory Throughput                   %         49.97
    DRAM Throughput                     %          7.10
    Duration                      msecond         46.71
    L1/TEX Cache Throughput             %         99.93
    L2 Cache Throughput                 %         13.96
    SM Active Cycles                cycle 44,811,954.27
    Compute (SM) Throughput             %         39.98
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                131,072
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                              273.07
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 75%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           36
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.90
    Achieved Active Warps Per SM           warp        15.97
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 2 8 1024 1024 gpu
CLI arguments: block_x = 2, block_y = 8, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 7457 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.786527 seconds.
==PROF== Disconnected from process 7457
[7457] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (512, 128, 1)x(2, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.53
    SM Frequency            cycle/usecond        936.31
    Elapsed Cycles                  cycle    40,360,966
    Memory Throughput                   %         49.95
    DRAM Throughput                     %          4.03
    Duration                      msecond         43.10
    L1/TEX Cache Throughput             %         99.90
    L2 Cache Throughput                 %          7.05
    SM Active Cycles                cycle 40,324,240.90
    Compute (SM) Throughput             %         22.20
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 65,536
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                              136.53
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           36
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.86
    Achieved Active Warps Per SM           warp        15.96
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 2 16 1024 1024 gpu
CLI arguments: block_x = 2, block_y = 16, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 7530 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.786492 seconds.
==PROF== Disconnected from process 7530
[7530] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (512, 64, 1)x(2, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.54
    SM Frequency            cycle/usecond        937.89
    Elapsed Cycles                  cycle    38,141,947
    Memory Throughput                   %         49.91
    DRAM Throughput                     %          2.17
    Duration                      msecond         40.66
    L1/TEX Cache Throughput             %         99.82
    L2 Cache Throughput                 %          4.59
    SM Active Cycles                cycle 38,070,016.33
    Compute (SM) Throughput             %         11.75
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 32,768
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               68.27
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           36
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.75
    Achieved Active Warps Per SM           warp        15.92
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 2 32 1024 1024 gpu
CLI arguments: block_x = 2, block_y = 32, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 7590 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.794172 seconds.
==PROF== Disconnected from process 7590
[7590] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (512, 32, 1)x(2, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.54
    SM Frequency            cycle/usecond        938.78
    Elapsed Cycles                  cycle    38,172,324
    Memory Throughput                   %         49.88
    DRAM Throughput                     %          1.12
    Duration                      msecond         40.66
    L1/TEX Cache Throughput             %         99.75
    L2 Cache Throughput                 %          6.04
    SM Active Cycles                cycle 38,078,193.03
    Compute (SM) Throughput             %         11.74
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 16,384
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           18
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        97.04
    Achieved Active Warps Per SM           warp        31.05
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 2 64 1024 1024 gpu
CLI arguments: block_x = 2, block_y = 64, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 7641 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.745825 seconds.
==PROF== Disconnected from process 7641
[7641] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (512, 16, 1)x(2, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.54
    SM Frequency            cycle/usecond        938.14
    Elapsed Cycles                  cycle    38,254,815
    Memory Throughput                   %         49.77
    DRAM Throughput                     %          0.59
    Duration                      msecond         40.78
    L1/TEX Cache Throughput             %         99.54
    L2 Cache Throughput                 %          9.74
    SM Active Cycles                cycle 38,176,900.10
    Compute (SM) Throughput             %         11.71
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  8,192
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            9
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.85
    Achieved Active Warps Per SM           warp        31.63
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 2 128 1024 1024 gpu
CLI arguments: block_x = 2, block_y = 128, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 7692 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.786313 seconds.
==PROF== Disconnected from process 7692
[7692] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (512, 8, 1)x(2, 128, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.53
    SM Frequency            cycle/usecond        937.37
    Elapsed Cycles                  cycle    38,296,150
    Memory Throughput                   %         49.72
    DRAM Throughput                     %          0.33
    Duration                      msecond         40.85
    L1/TEX Cache Throughput             %         99.43
    L2 Cache Throughput                 %          9.48
    SM Active Cycles                cycle 38,128,264.97
    Compute (SM) Throughput             %         11.70
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  4,096
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.74
    Achieved Active Warps Per SM           warp        31.60
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 2 256 1024 1024 gpu
CLI arguments: block_x = 2, block_y = 256, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 7749 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.832136 seconds.
==PROF== Disconnected from process 7749
[7749] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (512, 4, 1)x(2, 256, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.58
    SM Frequency            cycle/usecond        943.94
    Elapsed Cycles                  cycle    38,564,841
    Memory Throughput                   %         49.36
    DRAM Throughput                     %          0.20
    Duration                      msecond         40.85
    L1/TEX Cache Throughput             %         98.73
    L2 Cache Throughput                 %          9.12
    SM Active Cycles                cycle 38,123,481.43
    Compute (SM) Throughput             %         11.62
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  2,048
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.82
    Achieved Active Warps Per SM           warp        31.62
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 2 512 1024 1024 gpu
CLI arguments: block_x = 2, block_y = 512, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 7810 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.759896 seconds.
==PROF== Disconnected from process 7810
[7810] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (512, 2, 1)x(2, 512, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.58
    SM Frequency            cycle/usecond        944.34
    Elapsed Cycles                  cycle    38,606,484
    Memory Throughput                   %         49.42
    DRAM Throughput                     %          0.17
    Duration                      msecond         40.88
    L1/TEX Cache Throughput             %         98.83
    L2 Cache Throughput                 %         21.27
    SM Active Cycles                cycle 38,087,652.37
    Compute (SM) Throughput             %         11.61
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,024
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            1
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.48
    Achieved Active Warps Per SM           warp        31.51
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 4 1 1024 1024 gpu
CLI arguments: block_x = 4, block_y = 1, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 7880 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.889698 seconds.
==PROF== Disconnected from process 7880
[7880] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (256, 1024, 1)x(4, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.50
    SM Frequency            cycle/usecond        933.29
    Elapsed Cycles                  cycle    45,234,537
    Memory Throughput                   %         79.24
    DRAM Throughput                     %         28.37
    Duration                      msecond         48.47
    L1/TEX Cache Throughput             %         79.25
    L2 Cache Throughput                 %         26.47
    SM Active Cycles                cycle 45,228,598.20
    Compute (SM) Throughput             %         79.24
    ----------------------- ------------- -------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     4
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                262,144
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                              546.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 87.5%                                                                                           
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           36
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.87
    Achieved Active Warps Per SM           warp        15.96
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 4 2 1024 1024 gpu
CLI arguments: block_x = 4, block_y = 2, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 7940 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.730017 seconds.
==PROF== Disconnected from process 7940
[7940] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (256, 512, 1)x(4, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.50
    SM Frequency            cycle/usecond        931.43
    Elapsed Cycles                  cycle    27,740,269
    Memory Throughput                   %         64.70
    DRAM Throughput                     %         23.15
    Duration                      msecond         29.74
    L1/TEX Cache Throughput             %         97.03
    L2 Cache Throughput                 %         22.03
    SM Active Cycles                cycle 27,684,056.20
    Compute (SM) Throughput             %         64.70
    ----------------------- ------------- -------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                131,072
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                              273.07
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 75%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           36
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.87
    Achieved Active Warps Per SM           warp        15.96
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 4 4 1024 1024 gpu
CLI arguments: block_x = 4, block_y = 4, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 7991 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.65812 seconds.
==PROF== Disconnected from process 7991
[7991] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (256, 256, 1)x(4, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.51
    SM Frequency            cycle/usecond        932.57
    Elapsed Cycles                  cycle    22,429,159
    Memory Throughput                   %         49.96
    DRAM Throughput                     %         14.34
    Duration                      msecond         24.04
    L1/TEX Cache Throughput             %         99.92
    L2 Cache Throughput                 %         15.03
    SM Active Cycles                cycle 22,405,560.30
    Compute (SM) Throughput             %         39.98
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 65,536
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                              136.53
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           36
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.85
    Achieved Active Warps Per SM           warp        15.95
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 4 8 1024 1024 gpu
CLI arguments: block_x = 4, block_y = 8, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 8045 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.604903 seconds.
==PROF== Disconnected from process 8045
[8045] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (256, 128, 1)x(4, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.57
    SM Frequency            cycle/usecond        936.03
    Elapsed Cycles                  cycle    20,199,327
    Memory Throughput                   %         49.91
    DRAM Throughput                     %          7.90
    Duration                      msecond         21.58
    L1/TEX Cache Throughput             %         99.82
    L2 Cache Throughput                 %          9.04
    SM Active Cycles                cycle 20,161,010.50
    Compute (SM) Throughput             %         22.19
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 32,768
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               68.27
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           36
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.75
    Achieved Active Warps Per SM           warp        15.92
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 4 16 1024 1024 gpu
CLI arguments: block_x = 4, block_y = 16, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 8103 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.623487 seconds.
==PROF== Disconnected from process 8103
[8103] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (256, 64, 1)x(4, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.57
    SM Frequency            cycle/usecond        935.59
    Elapsed Cycles                  cycle    20,214,573
    Memory Throughput                   %         49.87
    DRAM Throughput                     %          4.01
    Duration                      msecond         21.60
    L1/TEX Cache Throughput             %         99.74
    L2 Cache Throughput                 %          7.81
    SM Active Cycles                cycle 20,167,707.17
    Compute (SM) Throughput             %         22.17
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 16,384
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           18
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        97.30
    Achieved Active Warps Per SM           warp        31.14
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 4 32 1024 1024 gpu
CLI arguments: block_x = 4, block_y = 32, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 8170 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.596813 seconds.
==PROF== Disconnected from process 8170
[8170] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (256, 32, 1)x(4, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.56
    SM Frequency            cycle/usecond        936.17
    Elapsed Cycles                  cycle    20,250,642
    Memory Throughput                   %         49.79
    DRAM Throughput                     %          2.09
    Duration                      msecond         21.63
    L1/TEX Cache Throughput             %         99.58
    L2 Cache Throughput                 %          9.43
    SM Active Cycles                cycle 20,209,349.53
    Compute (SM) Throughput             %         22.13
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  8,192
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            9
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.88
    Achieved Active Warps Per SM           warp        31.64
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 4 64 1024 1024 gpu
CLI arguments: block_x = 4, block_y = 64, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 8227 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.601995 seconds.
==PROF== Disconnected from process 8227
[8227] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (256, 16, 1)x(4, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.58
    SM Frequency            cycle/usecond        936.68
    Elapsed Cycles                  cycle    20,252,698
    Memory Throughput                   %         49.78
    DRAM Throughput                     %          1.11
    Duration                      msecond         21.62
    L1/TEX Cache Throughput             %         99.57
    L2 Cache Throughput                 %          8.53
    SM Active Cycles                cycle 20,163,831.80
    Compute (SM) Throughput             %         22.12
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  4,096
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.78
    Achieved Active Warps Per SM           warp        31.61
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 4 128 1024 1024 gpu
CLI arguments: block_x = 4, block_y = 128, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 8275 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.599417 seconds.
==PROF== Disconnected from process 8275
[8275] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (256, 8, 1)x(4, 128, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.64
    SM Frequency            cycle/usecond        943.43
    Elapsed Cycles                  cycle    20,412,967
    Memory Throughput                   %         49.39
    DRAM Throughput                     %          0.61
    Duration                      msecond         21.64
    L1/TEX Cache Throughput             %         98.77
    L2 Cache Throughput                 %          8.12
    SM Active Cycles                cycle 20,178,590.30
    Compute (SM) Throughput             %         21.95
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  2,048
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.79
    Achieved Active Warps Per SM           warp        31.61
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 4 256 1024 1024 gpu
CLI arguments: block_x = 4, block_y = 256, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 8323 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.612159 seconds.
==PROF== Disconnected from process 8323
[8323] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (256, 4, 1)x(4, 256, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.66
    SM Frequency            cycle/usecond        944.22
    Elapsed Cycles                  cycle    20,402,702
    Memory Throughput                   %         49.40
    DRAM Throughput                     %          0.36
    Duration                      msecond         21.61
    L1/TEX Cache Throughput             %         98.80
    L2 Cache Throughput                 %          8.07
    SM Active Cycles                cycle 20,125,617.83
    Compute (SM) Throughput             %         21.96
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,024
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            1
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.19
    Achieved Active Warps Per SM           warp        31.42
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 8 1 1024 1024 gpu
CLI arguments: block_x = 8, block_y = 1, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 8374 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.716521 seconds.
==PROF== Disconnected from process 8374
[8374] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (128, 1024, 1)x(8, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.44
    SM Frequency            cycle/usecond        924.40
    Elapsed Cycles                  cycle    23,116,722
    Memory Throughput                   %         77.53
    DRAM Throughput                     %         54.53
    Duration                      msecond         25.01
    L1/TEX Cache Throughput             %         77.68
    L2 Cache Throughput                 %         26.57
    SM Active Cycles                cycle 23,070,103.93
    Compute (SM) Throughput             %         77.53
    ----------------------- ------------- -------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                131,072
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                              273.07
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 75%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           36
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.85
    Achieved Active Warps Per SM           warp        15.95
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 8 2 1024 1024 gpu
CLI arguments: block_x = 8, block_y = 2, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 8443 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.593298 seconds.
==PROF== Disconnected from process 8443
[8443] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (128, 512, 1)x(8, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.54
    SM Frequency            cycle/usecond        924.76
    Elapsed Cycles                  cycle    14,091,521
    Memory Throughput                   %         63.59
    DRAM Throughput                     %         44.03
    Duration                      msecond         15.24
    L1/TEX Cache Throughput             %         95.38
    L2 Cache Throughput                 %         22.97
    SM Active Cycles                cycle 14,078,172.50
    Compute (SM) Throughput             %         63.59
    ----------------------- ------------- -------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 65,536
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                              136.53
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           36
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.83
    Achieved Active Warps Per SM           warp        15.95
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 8 4 1024 1024 gpu
CLI arguments: block_x = 8, block_y = 4, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 8505 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.535949 seconds.
==PROF== Disconnected from process 8505
[8505] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (128, 256, 1)x(8, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.59
    SM Frequency            cycle/usecond        930.99
    Elapsed Cycles                  cycle    11,216,917
    Memory Throughput                   %         49.92
    DRAM Throughput                     %         27.69
    Duration                      msecond         12.05
    L1/TEX Cache Throughput             %         99.84
    L2 Cache Throughput                 %         15.63
    SM Active Cycles                cycle 11,206,734.67
    Compute (SM) Throughput             %         39.94
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 32,768
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               68.27
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           36
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.77
    Achieved Active Warps Per SM           warp        15.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 8 8 1024 1024 gpu
CLI arguments: block_x = 8, block_y = 8, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 8562 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.578391 seconds.
==PROF== Disconnected from process 8562
[8562] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (128, 128, 1)x(8, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.59
    SM Frequency            cycle/usecond       930.58
    Elapsed Cycles                  cycle   11,237,371
    Memory Throughput                   %        49.83
    DRAM Throughput                     %        13.88
    Duration                      msecond        12.08
    L1/TEX Cache Throughput             %        99.66
    L2 Cache Throughput                 %        12.60
    SM Active Cycles                cycle   11,212,240
    Compute (SM) Throughput             %        39.87
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 16,384
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           18
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        96.39
    Achieved Active Warps Per SM           warp        30.84
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 8 16 1024 1024 gpu
CLI arguments: block_x = 8, block_y = 16, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 8621 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.548712 seconds.
==PROF== Disconnected from process 8621
[8621] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (128, 64, 1)x(8, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.59
    SM Frequency            cycle/usecond        931.26
    Elapsed Cycles                  cycle    11,304,501
    Memory Throughput                   %         49.53
    DRAM Throughput                     %          7.19
    Duration                      msecond         12.14
    L1/TEX Cache Throughput             %         99.07
    L2 Cache Throughput                 %          9.96
    SM Active Cycles                cycle 11,290,481.80
    Compute (SM) Throughput             %         39.63
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  8,192
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            9
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.91
    Achieved Active Warps Per SM           warp        31.65
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 8 32 1024 1024 gpu
CLI arguments: block_x = 8, block_y = 32, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 8671 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.579557 seconds.
==PROF== Disconnected from process 8671
[8671] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (128, 32, 1)x(8, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.61
    SM Frequency            cycle/usecond        933.45
    Elapsed Cycles                  cycle    11,330,700
    Memory Throughput                   %         49.42
    DRAM Throughput                     %          3.70
    Duration                      msecond         12.14
    L1/TEX Cache Throughput             %         98.84
    L2 Cache Throughput                 %          8.26
    SM Active Cycles                cycle 11,306,344.77
    Compute (SM) Throughput             %         39.54
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  4,096
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.91
    Achieved Active Warps Per SM           warp        31.65
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 8 64 1024 1024 gpu
CLI arguments: block_x = 8, block_y = 64, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 8724 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.590396 seconds.
==PROF== Disconnected from process 8724
[8724] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (128, 16, 1)x(8, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.65
    SM Frequency            cycle/usecond        939.57
    Elapsed Cycles                  cycle    11,337,984
    Memory Throughput                   %         49.39
    DRAM Throughput                     %          1.96
    Duration                      msecond         12.07
    L1/TEX Cache Throughput             %         98.78
    L2 Cache Throughput                 %          7.50
    SM Active Cycles                cycle 11,213,297.20
    Compute (SM) Throughput             %         39.52
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  2,048
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.86
    Achieved Active Warps Per SM           warp        31.63
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 8 128 1024 1024 gpu
CLI arguments: block_x = 8, block_y = 128, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 8783 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.569441 seconds.
==PROF== Disconnected from process 8783
[8783] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (128, 8, 1)x(8, 128, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.67
    SM Frequency            cycle/usecond        942.02
    Elapsed Cycles                  cycle    11,352,209
    Memory Throughput                   %         49.33
    DRAM Throughput                     %          1.08
    Duration                      msecond         12.05
    L1/TEX Cache Throughput             %         98.66
    L2 Cache Throughput                 %          6.93
    SM Active Cycles                cycle 11,189,672.43
    Compute (SM) Throughput             %         39.47
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,024
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            1
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.54
    Achieved Active Warps Per SM           warp        31.53
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 16 1 1024 1024 gpu
CLI arguments: block_x = 16, block_y = 1, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 8843 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.596296 seconds.
==PROF== Disconnected from process 8843
[8843] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (64, 1024, 1)x(16, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.29
    SM Frequency            cycle/usecond        889.37
    Elapsed Cycles                  cycle    12,304,320
    Memory Throughput                   %         72.83
    DRAM Throughput                     %         70.37
    Duration                      msecond         13.83
    L1/TEX Cache Throughput             %         72.84
    L2 Cache Throughput                 %         49.14
    SM Active Cycles                cycle 12,675,242.53
    Compute (SM) Throughput             %         72.83
    ----------------------- ------------- -------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 65,536
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                              136.53
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           36
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.83
    Achieved Active Warps Per SM           warp        15.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 16 2 1024 1024 gpu
CLI arguments: block_x = 16, block_y = 2, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 8912 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.549569 seconds.
==PROF== Disconnected from process 8912
[8912] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (64, 512, 1)x(16, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.59
    SM Frequency            cycle/usecond       920.93
    Elapsed Cycles                  cycle    7,264,231
    Memory Throughput                   %        69.35
    DRAM Throughput                     %        69.35
    Duration                      msecond         7.86
    L1/TEX Cache Throughput             %        92.88
    L2 Cache Throughput                 %        43.24
    SM Active Cycles                cycle 7,198,152.03
    Compute (SM) Throughput             %        61.91
    ----------------------- ------------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 32,768
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               68.27
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           36
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.76
    Achieved Active Warps Per SM           warp        15.92
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 16 4 1024 1024 gpu
CLI arguments: block_x = 16, block_y = 4, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 8971 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.536973 seconds.
==PROF== Disconnected from process 8971
[8971] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (64, 256, 1)x(16, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.56
    SM Frequency            cycle/usecond       921.33
    Elapsed Cycles                  cycle    7,125,441
    Memory Throughput                   %        62.99
    DRAM Throughput                     %        40.19
    Duration                      msecond         7.72
    L1/TEX Cache Throughput             %        94.49
    L2 Cache Throughput                 %        30.65
    SM Active Cycles                cycle 7,100,862.20
    Compute (SM) Throughput             %        62.99
    ----------------------- ------------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 16,384
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           18
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        96.93
    Achieved Active Warps Per SM           warp        31.02
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 16 8 1024 1024 gpu
CLI arguments: block_x = 16, block_y = 8, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 9021 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.52529 seconds.
==PROF== Disconnected from process 9021
[9021] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (64, 128, 1)x(16, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.80
    SM Frequency            cycle/usecond       923.87
    Elapsed Cycles                  cycle    7,272,401
    Memory Throughput                   %        62.21
    DRAM Throughput                     %        20.96
    Duration                      msecond         7.80
    L1/TEX Cache Throughput             %        93.33
    L2 Cache Throughput                 %        16.25
    SM Active Cycles                cycle 7,192,224.83
    Compute (SM) Throughput             %        62.21
    ----------------------- ------------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  8,192
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            9
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.96
    Achieved Active Warps Per SM           warp        31.67
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 16 16 1024 1024 gpu
CLI arguments: block_x = 16, block_y = 16, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 9071 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.552148 seconds.
==PROF== Disconnected from process 9071
[9071] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (64, 64, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.61
    SM Frequency            cycle/usecond       925.70
    Elapsed Cycles                  cycle    7,190,010
    Memory Throughput                   %        62.41
    DRAM Throughput                     %        11.21
    Duration                      msecond         7.76
    L1/TEX Cache Throughput             %        93.63
    L2 Cache Throughput                 %        10.40
    SM Active Cycles                cycle 7,152,765.93
    Compute (SM) Throughput             %        62.41
    ----------------------- ------------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  4,096
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.96
    Achieved Active Warps Per SM           warp        31.67
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 16 32 1024 1024 gpu
CLI arguments: block_x = 16, block_y = 32, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 9121 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.543254 seconds.
==PROF== Disconnected from process 9121
[9121] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (64, 32, 1)x(16, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.79
    SM Frequency            cycle/usecond       928.44
    Elapsed Cycles                  cycle    7,445,346
    Memory Throughput                   %        60.63
    DRAM Throughput                     %         5.48
    Duration                      msecond         7.96
    L1/TEX Cache Throughput             %        90.97
    L2 Cache Throughput                 %         7.84
    SM Active Cycles                cycle 7,336,780.80
    Compute (SM) Throughput             %        60.63
    ----------------------- ------------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  2,048
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.93
    Achieved Active Warps Per SM           warp        31.66
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 16 64 1024 1024 gpu
CLI arguments: block_x = 16, block_y = 64, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 9171 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.565877 seconds.
==PROF== Disconnected from process 9171
[9171] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (64, 16, 1)x(16, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.79
    SM Frequency            cycle/usecond       927.98
    Elapsed Cycles                  cycle    7,043,239
    Memory Throughput                   %        64.13
    DRAM Throughput                     %         3.07
    Duration                      msecond         7.53
    L1/TEX Cache Throughput             %        96.22
    L2 Cache Throughput                 %         6.84
    SM Active Cycles                cycle 6,855,162.63
    Compute (SM) Throughput             %        64.13
    ----------------------- ------------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,024
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            1
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.75
    Achieved Active Warps Per SM           warp        31.60
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 32 1 1024 1024 gpu
CLI arguments: block_x = 32, block_y = 1, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 9234 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.641113 seconds.
==PROF== Disconnected from process 9234
[9234] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (32, 1024, 1)x(32, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.51
    SM Frequency            cycle/usecond       917.96
    Elapsed Cycles                  cycle    7,843,691
    Memory Throughput                   %        82.65
    DRAM Throughput                     %        82.65
    Duration                      msecond         8.54
    L1/TEX Cache Throughput             %        58.63
    L2 Cache Throughput                 %        76.47
    SM Active Cycles                cycle 7,778,616.80
    Compute (SM) Throughput             %        57.17
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing DRAM in the Memory Workload Analysis section.                                              

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 32,768
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               68.27
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           36
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.79
    Achieved Active Warps Per SM           warp        15.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 32 2 1024 1024 gpu
CLI arguments: block_x = 32, block_y = 2, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 9306 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.579723 seconds.
==PROF== Disconnected from process 9306
[9306] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (32, 512, 1)x(32, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.79
    SM Frequency            cycle/usecond       911.31
    Elapsed Cycles                  cycle    5,833,898
    Memory Throughput                   %        78.71
    DRAM Throughput                     %        60.02
    Duration                      msecond         6.28
    L1/TEX Cache Throughput             %        78.36
    L2 Cache Throughput                 %        78.71
    SM Active Cycles                cycle 5,717,783.10
    Compute (SM) Throughput             %        78.23
    ----------------------- ------------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 16,384
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           18
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        97.12
    Achieved Active Warps Per SM           warp        31.08
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 32 4 1024 1024 gpu
CLI arguments: block_x = 32, block_y = 4, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 9365 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.559395 seconds.
==PROF== Disconnected from process 9365
[9365] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (32, 256, 1)x(32, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.80
    SM Frequency            cycle/usecond       918.21
    Elapsed Cycles                  cycle    5,799,653
    Memory Throughput                   %        78.35
    DRAM Throughput                     %        48.42
    Duration                      msecond         6.23
    L1/TEX Cache Throughput             %        78.51
    L2 Cache Throughput                 %        30.84
    SM Active Cycles                cycle 5,707,224.67
    Compute (SM) Throughput             %        78.35
    ----------------------- ------------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  8,192
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            9
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.98
    Achieved Active Warps Per SM           warp        31.67
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 32 8 1024 1024 gpu
CLI arguments: block_x = 32, block_y = 8, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 9415 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.563269 seconds.
==PROF== Disconnected from process 9415
[9415] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (32, 128, 1)x(32, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.79
    SM Frequency            cycle/usecond       920.64
    Elapsed Cycles                  cycle    5,761,683
    Memory Throughput                   %        78.62
    DRAM Throughput                     %        26.26
    Duration                      msecond         6.19
    L1/TEX Cache Throughput             %        78.86
    L2 Cache Throughput                 %        16.70
    SM Active Cycles                cycle 5,681,647.50
    Compute (SM) Throughput             %        78.62
    ----------------------- ------------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  4,096
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.97
    Achieved Active Warps Per SM           warp        31.67
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 32 16 1024 1024 gpu
CLI arguments: block_x = 32, block_y = 16, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 9465 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.561239 seconds.
==PROF== Disconnected from process 9465
[9465] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (32, 64, 1)x(32, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.80
    SM Frequency            cycle/usecond       923.64
    Elapsed Cycles                  cycle    5,875,727
    Memory Throughput                   %        76.98
    DRAM Throughput                     %        13.14
    Duration                      msecond         6.30
    L1/TEX Cache Throughput             %        77.33
    L2 Cache Throughput                 %         9.80
    SM Active Cycles                cycle    5,793,614
    Compute (SM) Throughput             %        76.98
    ----------------------- ------------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  2,048
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        99.05
    Achieved Active Warps Per SM           warp        31.70
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 32 32 1024 1024 gpu
CLI arguments: block_x = 32, block_y = 32, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 9515 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.570612 seconds.
==PROF== Disconnected from process 9515
[9515] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (32, 32, 1)x(32, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.80
    SM Frequency            cycle/usecond       923.46
    Elapsed Cycles                  cycle    5,423,982
    Memory Throughput                   %        83.39
    DRAM Throughput                     %         7.56
    Duration                      msecond         5.82
    L1/TEX Cache Throughput             %        84.88
    L2 Cache Throughput                 %         7.12
    SM Active Cycles                cycle 5,278,660.20
    Compute (SM) Throughput             %        83.39
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,024
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            1
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.97
    Achieved Active Warps Per SM           warp        31.67
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 64 1 1024 1024 gpu
CLI arguments: block_x = 64, block_y = 1, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 9575 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.556036 seconds.
==PROF== Disconnected from process 9575
[9575] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (16, 1024, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.70
    SM Frequency            cycle/usecond       910.11
    Elapsed Cycles                  cycle    6,704,712
    Memory Throughput                   %        90.56
    DRAM Throughput                     %        69.53
    Duration                      msecond         7.28
    L1/TEX Cache Throughput             %        67.74
    L2 Cache Throughput                 %        90.56
    SM Active Cycles                cycle 6,646,700.53
    Compute (SM) Throughput             %        67.60
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing L2 in the Memory Workload Analysis section.                                                

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 16,384
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           18
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        97.43
    Achieved Active Warps Per SM           warp        31.18
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 64 2 1024 1024 gpu
CLI arguments: block_x = 64, block_y = 2, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 9639 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.540488 seconds.
==PROF== Disconnected from process 9639
[9639] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (16, 512, 1)x(64, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.80
    SM Frequency            cycle/usecond       914.39
    Elapsed Cycles                  cycle    5,806,287
    Memory Throughput                   %        78.44
    DRAM Throughput                     %        57.23
    Duration                      msecond         6.25
    L1/TEX Cache Throughput             %        78.67
    L2 Cache Throughput                 %        64.45
    SM Active Cycles                cycle 5,695,196.60
    Compute (SM) Throughput             %        78.44
    ----------------------- ------------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  8,192
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            9
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.65
    Achieved Active Warps Per SM           warp        31.57
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 64 4 1024 1024 gpu
CLI arguments: block_x = 64, block_y = 4, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 9694 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.552267 seconds.
==PROF== Disconnected from process 9694
[9694] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (16, 256, 1)x(64, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.79
    SM Frequency            cycle/usecond       918.22
    Elapsed Cycles                  cycle    5,606,178
    Memory Throughput                   %        80.96
    DRAM Throughput                     %        30.17
    Duration                      msecond         6.03
    L1/TEX Cache Throughput             %        81.00
    L2 Cache Throughput                 %        29.52
    SM Active Cycles                cycle 5,553,901.43
    Compute (SM) Throughput             %        80.96
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  4,096
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.63
    Achieved Active Warps Per SM           warp        31.56
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 64 8 1024 1024 gpu
CLI arguments: block_x = 64, block_y = 8, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 9753 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.553159 seconds.
==PROF== Disconnected from process 9753
[9753] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (16, 128, 1)x(64, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.78
    SM Frequency            cycle/usecond       920.66
    Elapsed Cycles                  cycle    5,510,082
    Memory Throughput                   %        82.18
    DRAM Throughput                     %        14.74
    Duration                      msecond         5.92
    L1/TEX Cache Throughput             %        82.87
    L2 Cache Throughput                 %        15.68
    SM Active Cycles                cycle 5,406,549.73
    Compute (SM) Throughput             %        82.18
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  2,048
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.57
    Achieved Active Warps Per SM           warp        31.54
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 64 16 1024 1024 gpu
CLI arguments: block_x = 64, block_y = 16, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 9803 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.541652 seconds.
==PROF== Disconnected from process 9803
[9803] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (16, 64, 1)x(64, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.79
    SM Frequency            cycle/usecond       922.87
    Elapsed Cycles                  cycle    5,311,093
    Memory Throughput                   %        85.26
    DRAM Throughput                     %         8.26
    Duration                      msecond         5.69
    L1/TEX Cache Throughput             %        87.40
    L2 Cache Throughput                 %         9.06
    SM Active Cycles                cycle 5,126,345.23
    Compute (SM) Throughput             %        85.26
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,024
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            1
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        99.04
    Achieved Active Warps Per SM           warp        31.69
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 128 1 1024 1024 gpu
CLI arguments: block_x = 128, block_y = 1, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 9853 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.552794 seconds.
==PROF== Disconnected from process 9853
[9853] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (8, 1024, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.78
    SM Frequency            cycle/usecond       911.63
    Elapsed Cycles                  cycle    6,850,611
    Memory Throughput                   %        89.28
    DRAM Throughput                     %        78.91
    Duration                      msecond         7.40
    L1/TEX Cache Throughput             %        67.05
    L2 Cache Throughput                 %        89.28
    SM Active Cycles                cycle 6,723,581.97
    Compute (SM) Throughput             %        66.40
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing L2 in the Memory Workload Analysis section.                                                

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  8,192
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            9
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.29
    Achieved Active Warps Per SM           warp        31.45
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 128 2 1024 1024 gpu
CLI arguments: block_x = 128, block_y = 2, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 9903 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.58811 seconds.
==PROF== Disconnected from process 9903
[9903] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (8, 512, 1)x(128, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.79
    SM Frequency            cycle/usecond       913.16
    Elapsed Cycles                  cycle    5,586,797
    Memory Throughput                   %        81.57
    DRAM Throughput                     %        30.05
    Duration                      msecond         6.02
    L1/TEX Cache Throughput             %        82.21
    L2 Cache Throughput                 %        61.69
    SM Active Cycles                cycle 5,450,025.50
    Compute (SM) Throughput             %        81.57
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  4,096
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.42
    Achieved Active Warps Per SM           warp        31.50
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 128 4 1024 1024 gpu
CLI arguments: block_x = 128, block_y = 4, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 9963 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.585734 seconds.
==PROF== Disconnected from process 9963
[9963] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (8, 256, 1)x(128, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.80
    SM Frequency            cycle/usecond       920.54
    Elapsed Cycles                  cycle    5,370,737
    Memory Throughput                   %        84.39
    DRAM Throughput                     %        14.26
    Duration                      msecond         5.77
    L1/TEX Cache Throughput             %        85.56
    L2 Cache Throughput                 %        29.80
    SM Active Cycles                cycle 5,236,514.63
    Compute (SM) Throughput             %        84.39
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  2,048
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.32
    Achieved Active Warps Per SM           warp        31.46
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 128 8 1024 1024 gpu
CLI arguments: block_x = 128, block_y = 8, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 10032 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.5447 seconds.
==PROF== Disconnected from process 10032
[10032] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (8, 128, 1)x(128, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.79
    SM Frequency            cycle/usecond       920.35
    Elapsed Cycles                  cycle    5,241,954
    Memory Throughput                   %        86.56
    DRAM Throughput                     %         8.35
    Duration                      msecond         5.62
    L1/TEX Cache Throughput             %        88.72
    L2 Cache Throughput                 %        15.56
    SM Active Cycles                cycle 5,050,225.97
    Compute (SM) Throughput             %        86.56
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,024
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            1
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        99.09
    Achieved Active Warps Per SM           warp        31.71
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 256 1 1024 1024 gpu
CLI arguments: block_x = 256, block_y = 1, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 10091 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.55934 seconds.
==PROF== Disconnected from process 10091
[10091] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (4, 1024, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.70
    SM Frequency            cycle/usecond       909.93
    Elapsed Cycles                  cycle    6,775,843
    Memory Throughput                   %        89.37
    DRAM Throughput                     %        69.49
    Duration                      msecond         7.36
    L1/TEX Cache Throughput             %        66.97
    L2 Cache Throughput                 %        89.37
    SM Active Cycles                cycle 6,710,625.50
    Compute (SM) Throughput             %        66.92
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing L2 in the Memory Workload Analysis section.                                                

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  4,096
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            4
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        97.10
    Achieved Active Warps Per SM           warp        31.07
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 256 2 1024 1024 gpu
CLI arguments: block_x = 256, block_y = 2, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 10141 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.542892 seconds.
==PROF== Disconnected from process 10141
[10141] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (4, 512, 1)x(256, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.82
    SM Frequency            cycle/usecond       920.43
    Elapsed Cycles                  cycle    5,472,153
    Memory Throughput                   %        83.05
    DRAM Throughput                     %        14.54
    Duration                      msecond         5.86
    L1/TEX Cache Throughput             %        84.04
    L2 Cache Throughput                 %        60.48
    SM Active Cycles                cycle 5,331,252.20
    Compute (SM) Throughput             %        83.05
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  2,048
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.48
    Achieved Active Warps Per SM           warp        31.51
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 256 4 1024 1024 gpu
CLI arguments: block_x = 256, block_y = 4, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 10191 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.566837 seconds.
==PROF== Disconnected from process 10191
[10191] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (4, 256, 1)x(256, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.80
    SM Frequency            cycle/usecond       919.13
    Elapsed Cycles                  cycle    5,243,447
    Memory Throughput                   %        86.63
    DRAM Throughput                     %         8.47
    Duration                      msecond         5.63
    L1/TEX Cache Throughput             %        88.81
    L2 Cache Throughput                 %        37.03
    SM Active Cycles                cycle 5,045,135.07
    Compute (SM) Throughput             %        86.63
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,024
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            1
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        99.00
    Achieved Active Warps Per SM           warp        31.68
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 512 1 1024 1024 gpu
CLI arguments: block_x = 512, block_y = 1, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 10241 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.547525 seconds.
==PROF== Disconnected from process 10241
[10241] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (2, 1024, 1)x(512, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.78
    SM Frequency            cycle/usecond       913.78
    Elapsed Cycles                  cycle    6,777,202
    Memory Throughput                   %        89.92
    DRAM Throughput                     %        54.75
    Duration                      msecond         7.31
    L1/TEX Cache Throughput             %        67.44
    L2 Cache Throughput                 %        89.92
    SM Active Cycles                cycle 6,646,603.30
    Compute (SM) Throughput             %        67.07
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing L2 in the Memory Workload Analysis section.                                                

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  2,048
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        97.09
    Achieved Active Warps Per SM           warp        31.07
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 512 2 1024 1024 gpu
CLI arguments: block_x = 512, block_y = 2, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 10291 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.549706 seconds.
==PROF== Disconnected from process 10291
[10291] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (2, 512, 1)x(512, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.80
    SM Frequency            cycle/usecond       916.29
    Elapsed Cycles                  cycle    5,681,887
    Memory Throughput                   %        80.73
    DRAM Throughput                     %         9.78
    Duration                      msecond         6.10
    L1/TEX Cache Throughput             %        81.12
    L2 Cache Throughput                 %        80.73
    SM Active Cycles                cycle 5,523,073.60
    Compute (SM) Throughput             %        80.12
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing L2 in the Memory Workload Analysis section.                                                

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,024
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            1
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.74
    Achieved Active Warps Per SM           warp        31.60
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_output in directory: ./attention/build with args: 1024 1 1024 1024 gpu
CLI arguments: block_x = 1024, block_y = 1, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 10351 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_output": 0%....50%....100% - 8 passes
GPU forward pass took 0.569735 seconds.
==PROF== Disconnected from process 10351
[10351] attention_solver@127.0.0.1
  compute_output(float *, float *, float *, int, int) (1, 1024, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.77
    SM Frequency            cycle/usecond       909.70
    Elapsed Cycles                  cycle    6,814,954
    Memory Throughput                   %        89.30
    DRAM Throughput                     %        59.11
    Duration                      msecond         7.37
    L1/TEX Cache Throughput             %        67.42
    L2 Cache Throughput                 %        89.30
    SM Active Cycles                cycle 6,645,489.73
    Compute (SM) Throughput             %        66.80
    ----------------------- ------------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing L2 in the Memory Workload Analysis section.                                                

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,024
    Registers Per Thread             register/thread              49
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            1
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.62
    Achieved Active Warps Per SM           warp        31.56
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 1 1 1024 1024 gpu
CLI arguments: block_x = 1, block_y = 1, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 10423 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 1.95177 seconds.
==PROF== Disconnected from process 10423
[10423] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (1024, 1024, 1)x(1, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- --------------
    Metric Name               Metric Unit   Metric Value
    ----------------------- ------------- --------------
    DRAM Frequency          cycle/nsecond           6.78
    SM Frequency            cycle/usecond         972.50
    Elapsed Cycles                  cycle    168,766,548
    Memory Throughput                   %          84.99
    DRAM Throughput                     %           7.63
    Duration                      msecond         173.48
    L1/TEX Cache Throughput             %          84.99
    L2 Cache Throughput                 %           3.69
    SM Active Cycles                cycle 168,699,673.30
    Compute (SM) Throughput             %          84.99
    ----------------------- ------------- --------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     1
    Function Cache Configuration                     CachePreferNone
    Grid Size                                              1,048,576
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                            2,184.53
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 96.88%                                                                                          
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 1      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           40
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.88
    Achieved Active Warps Per SM           warp        15.96
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 1 2 1024 1024 gpu
CLI arguments: block_x = 1, block_y = 2, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 10503 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 1.38938 seconds.
==PROF== Disconnected from process 10503
[10503] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (1024, 512, 1)x(1, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- --------------
    Metric Name               Metric Unit   Metric Value
    ----------------------- ------------- --------------
    DRAM Frequency          cycle/nsecond           6.71
    SM Frequency            cycle/usecond         963.30
    Elapsed Cycles                  cycle    108,797,006
    Memory Throughput                   %          65.90
    DRAM Throughput                     %           5.93
    Duration                      msecond         112.92
    L1/TEX Cache Throughput             %          98.84
    L2 Cache Throughput                 %           3.00
    SM Active Cycles                cycle 108,766,780.50
    Compute (SM) Throughput             %          65.90
    ----------------------- ------------- --------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     2
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                524,288
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                            1,092.27
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 93.75%                                                                                          
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 2      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           40
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.90
    Achieved Active Warps Per SM           warp        15.97
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 1 4 1024 1024 gpu
CLI arguments: block_x = 1, block_y = 4, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 10578 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 1.21755 seconds.
==PROF== Disconnected from process 10578
[10578] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (1024, 256, 1)x(1, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.67
    SM Frequency            cycle/usecond        956.40
    Elapsed Cycles                  cycle    89,630,511
    Memory Throughput                   %         49.98
    DRAM Throughput                     %          3.61
    Duration                      msecond         93.71
    L1/TEX Cache Throughput             %         99.96
    L2 Cache Throughput                 %          1.99
    SM Active Cycles                cycle 89,602,472.50
    Compute (SM) Throughput             %         39.99
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     4
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                262,144
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                              546.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 87.5%                                                                                           
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           40
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.92
    Achieved Active Warps Per SM           warp        15.97
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 1 8 1024 1024 gpu
CLI arguments: block_x = 1, block_y = 8, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 10656 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 1.14073 seconds.
==PROF== Disconnected from process 10656
[10656] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (1024, 128, 1)x(1, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.67
    SM Frequency            cycle/usecond        957.52
    Elapsed Cycles                  cycle    80,659,345
    Memory Throughput                   %         49.98
    DRAM Throughput                     %          2.01
    Duration                      msecond         84.23
    L1/TEX Cache Throughput             %         99.96
    L2 Cache Throughput                 %          1.46
    SM Active Cycles                cycle 80,626,854.33
    Compute (SM) Throughput             %         22.22
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                131,072
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                              273.07
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 75%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           40
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.91
    Achieved Active Warps Per SM           warp        15.97
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 1 16 1024 1024 gpu
CLI arguments: block_x = 1, block_y = 16, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 10733 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 1.09652 seconds.
==PROF== Disconnected from process 10733
[10733] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (1024, 64, 1)x(1, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.63
    SM Frequency            cycle/usecond        951.02
    Elapsed Cycles                  cycle    76,252,302
    Memory Throughput                   %         49.96
    DRAM Throughput                     %          1.08
    Duration                      msecond         80.18
    L1/TEX Cache Throughput             %         99.92
    L2 Cache Throughput                 %          2.38
    SM Active Cycles                cycle 76,187,185.40
    Compute (SM) Throughput             %         11.75
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 65,536
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                              136.53
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           40
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.86
    Achieved Active Warps Per SM           warp        15.95
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 1 32 1024 1024 gpu
CLI arguments: block_x = 1, block_y = 32, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 10798 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 1.12008 seconds.
==PROF== Disconnected from process 10798
[10798] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (1024, 32, 1)x(1, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.64
    SM Frequency            cycle/usecond        952.98
    Elapsed Cycles                  cycle    73,989,906
    Memory Throughput                   %         49.94
    DRAM Throughput                     %          0.58
    Duration                      msecond         77.64
    L1/TEX Cache Throughput             %         99.88
    L2 Cache Throughput                 %          2.35
    SM Active Cycles                cycle 73,894,022.70
    Compute (SM) Throughput             %          6.06
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 32,768
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               68.27
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           40
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.75
    Achieved Active Warps Per SM           warp        15.92
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 1 64 1024 1024 gpu
CLI arguments: block_x = 1, block_y = 64, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 10867 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 1.10484 seconds.
==PROF== Disconnected from process 10867
[10867] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (1024, 16, 1)x(1, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.63
    SM Frequency            cycle/usecond        952.02
    Elapsed Cycles                  cycle    74,125,370
    Memory Throughput                   %         49.85
    DRAM Throughput                     %          0.31
    Duration                      msecond         77.86
    L1/TEX Cache Throughput             %         99.71
    L2 Cache Throughput                 %          5.67
    SM Active Cycles                cycle 73,968,453.47
    Compute (SM) Throughput             %          6.04
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 16,384
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           20
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        97.49
    Achieved Active Warps Per SM           warp        31.20
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 1 128 1024 1024 gpu
CLI arguments: block_x = 1, block_y = 128, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 10954 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 1.12508 seconds.
==PROF== Disconnected from process 10954
[10954] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (1024, 8, 1)x(1, 128, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.61
    SM Frequency            cycle/usecond        948.92
    Elapsed Cycles                  cycle    74,508,094
    Memory Throughput                   %         49.62
    DRAM Throughput                     %          0.17
    Duration                      msecond         78.50
    L1/TEX Cache Throughput             %         99.24
    L2 Cache Throughput                 %         13.98
    SM Active Cycles                cycle 74,362,835.90
    Compute (SM) Throughput             %          6.02
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  8,192
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.76
    Achieved Active Warps Per SM           warp        31.60
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 1 256 1024 1024 gpu
CLI arguments: block_x = 1, block_y = 256, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 11022 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 1.10405 seconds.
==PROF== Disconnected from process 11022
[11022] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (1024, 4, 1)x(1, 256, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.63
    SM Frequency            cycle/usecond        951.03
    Elapsed Cycles                  cycle    74,622,693
    Memory Throughput                   %         49.54
    DRAM Throughput                     %          0.10
    Duration                      msecond         78.45
    L1/TEX Cache Throughput             %         99.08
    L2 Cache Throughput                 %         14.48
    SM Active Cycles                cycle 74,293,207.27
    Compute (SM) Throughput             %          6.01
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  4,096
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.89
    Achieved Active Warps Per SM           warp        31.65
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 1 512 1024 1024 gpu
CLI arguments: block_x = 1, block_y = 512, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 11078 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 1.07542 seconds.
==PROF== Disconnected from process 11078
[11078] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (1024, 2, 1)x(1, 512, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.60
    SM Frequency            cycle/usecond        946.44
    Elapsed Cycles                  cycle    74,659,591
    Memory Throughput                   %         49.55
    DRAM Throughput                     %          0.08
    Duration                      msecond         78.86
    L1/TEX Cache Throughput             %         99.11
    L2 Cache Throughput                 %         17.59
    SM Active Cycles                cycle 74,204,995.43
    Compute (SM) Throughput             %          6.00
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  2,048
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        99.16
    Achieved Active Warps Per SM           warp        31.73
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 1 1024 1024 1024 gpu
CLI arguments: block_x = 1, block_y = 1024, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 11147 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 1.09267 seconds.
==PROF== Disconnected from process 11147
[11147] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (1024, 1, 1)x(1, 1024, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.72
    SM Frequency            cycle/usecond        963.60
    Elapsed Cycles                  cycle    76,537,423
    Memory Throughput                   %         54.31
    DRAM Throughput                     %          0.61
    Duration                      msecond         79.34
    L1/TEX Cache Throughput             %         97.03
    L2 Cache Throughput                 %         54.31
    SM Active Cycles                cycle 74,508,151.30
    Compute (SM) Throughput             %          5.86
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,024
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            1
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.83
    Achieved Active Warps Per SM           warp        31.62
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 2 1 1024 1024 gpu
CLI arguments: block_x = 2, block_y = 1, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 11238 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 1.45241 seconds.
==PROF== Disconnected from process 11238
[11238] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (512, 1024, 1)x(2, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- --------------
    Metric Name               Metric Unit   Metric Value
    ----------------------- ------------- --------------
    DRAM Frequency          cycle/nsecond           6.73
    SM Frequency            cycle/usecond         965.89
    Elapsed Cycles                  cycle    112,913,973
    Memory Throughput                   %          63.51
    DRAM Throughput                     %          11.39
    Duration                      msecond         116.86
    L1/TEX Cache Throughput             %          95.22
    L2 Cache Throughput                 %           5.53
    SM Active Cycles                cycle 112,843,812.90
    Compute (SM) Throughput             %          63.51
    ----------------------- ------------- --------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     2
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                524,288
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                            1,092.27
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 93.75%                                                                                          
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 2      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           40
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.90
    Achieved Active Warps Per SM           warp        15.97
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 2 2 1024 1024 gpu
CLI arguments: block_x = 2, block_y = 2, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 11306 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 1.05652 seconds.
==PROF== Disconnected from process 11306
[11306] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (512, 512, 1)x(2, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.63
    SM Frequency            cycle/usecond        950.73
    Elapsed Cycles                  cycle    71,944,780
    Memory Throughput                   %         49.84
    DRAM Throughput                     %          8.94
    Duration                      msecond         75.65
    L1/TEX Cache Throughput             %         99.63
    L2 Cache Throughput                 %          4.55
    SM Active Cycles                cycle 71,914,843.47
    Compute (SM) Throughput             %         49.84
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     4
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                262,144
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                              546.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 87.5%                                                                                           
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           40
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.91
    Achieved Active Warps Per SM           warp        15.97
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 2 4 1024 1024 gpu
CLI arguments: block_x = 2, block_y = 4, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 11365 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.950884 seconds.
==PROF== Disconnected from process 11365
[11365] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (512, 256, 1)x(2, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.57
    SM Frequency            cycle/usecond       942.05
    Elapsed Cycles                  cycle   53,771,770
    Memory Throughput                   %        49.98
    DRAM Throughput                     %         5.92
    Duration                      msecond        57.07
    L1/TEX Cache Throughput             %        99.97
    L2 Cache Throughput                 %         3.37
    SM Active Cycles                cycle   53,743,354
    Compute (SM) Throughput             %        33.34
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                131,072
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                              273.07
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 75%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           40
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.90
    Achieved Active Warps Per SM           warp        15.97
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 2 8 1024 1024 gpu
CLI arguments: block_x = 2, block_y = 8, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 11445 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.832301 seconds.
==PROF== Disconnected from process 11445
[11445] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (512, 128, 1)x(2, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.52
    SM Frequency            cycle/usecond        935.40
    Elapsed Cycles                  cycle    44,873,112
    Memory Throughput                   %         49.97
    DRAM Throughput                     %          3.53
    Duration                      msecond         47.96
    L1/TEX Cache Throughput             %         99.93
    L2 Cache Throughput                 %          2.86
    SM Active Cycles                cycle 44,832,860.47
    Compute (SM) Throughput             %         19.97
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 65,536
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                              136.53
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           40
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.85
    Achieved Active Warps Per SM           warp        15.95
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 2 16 1024 1024 gpu
CLI arguments: block_x = 2, block_y = 16, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 11515 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.779766 seconds.
==PROF== Disconnected from process 11515
[11515] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (512, 64, 1)x(2, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.52
    SM Frequency            cycle/usecond        935.02
    Elapsed Cycles                  cycle    40,364,706
    Memory Throughput                   %         49.94
    DRAM Throughput                     %          2.00
    Duration                      msecond         43.16
    L1/TEX Cache Throughput             %         99.89
    L2 Cache Throughput                 %          2.85
    SM Active Cycles                cycle 40,309,741.83
    Compute (SM) Throughput             %         11.10
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 32,768
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               68.27
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           40
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.73
    Achieved Active Warps Per SM           warp        15.91
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 2 32 1024 1024 gpu
CLI arguments: block_x = 2, block_y = 32, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 11574 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.809686 seconds.
==PROF== Disconnected from process 11574
[11574] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (512, 32, 1)x(2, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.52
    SM Frequency            cycle/usecond        934.95
    Elapsed Cycles                  cycle    40,351,275
    Memory Throughput                   %         49.95
    DRAM Throughput                     %          1.03
    Duration                      msecond         43.16
    L1/TEX Cache Throughput             %         99.90
    L2 Cache Throughput                 %          4.42
    SM Active Cycles                cycle 40,288,682.37
    Compute (SM) Throughput             %         11.10
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 16,384
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           20
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        97.28
    Achieved Active Warps Per SM           warp        31.13
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 2 64 1024 1024 gpu
CLI arguments: block_x = 2, block_y = 64, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 11627 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.820616 seconds.
==PROF== Disconnected from process 11627
[11627] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (512, 16, 1)x(2, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.53
    SM Frequency            cycle/usecond        936.56
    Elapsed Cycles                  cycle    40,407,242
    Memory Throughput                   %         49.89
    DRAM Throughput                     %          0.56
    Duration                      msecond         43.14
    L1/TEX Cache Throughput             %         99.79
    L2 Cache Throughput                 %          8.20
    SM Active Cycles                cycle 40,329,592.73
    Compute (SM) Throughput             %         11.09
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  8,192
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.70
    Achieved Active Warps Per SM           warp        31.58
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 2 128 1024 1024 gpu
CLI arguments: block_x = 2, block_y = 128, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 11683 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.811703 seconds.
==PROF== Disconnected from process 11683
[11683] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (512, 8, 1)x(2, 128, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.53
    SM Frequency            cycle/usecond        937.38
    Elapsed Cycles                  cycle    40,529,532
    Memory Throughput                   %         49.74
    DRAM Throughput                     %          0.31
    Duration                      msecond         43.23
    L1/TEX Cache Throughput             %         99.48
    L2 Cache Throughput                 %          8.55
    SM Active Cycles                cycle 40,340,038.23
    Compute (SM) Throughput             %         11.06
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  4,096
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.86
    Achieved Active Warps Per SM           warp        31.63
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 2 256 1024 1024 gpu
CLI arguments: block_x = 2, block_y = 256, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 11756 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.792425 seconds.
==PROF== Disconnected from process 11756
[11756] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (512, 4, 1)x(2, 256, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.57
    SM Frequency            cycle/usecond        942.99
    Elapsed Cycles                  cycle    40,824,426
    Memory Throughput                   %         49.37
    DRAM Throughput                     %          0.18
    Duration                      msecond         43.29
    L1/TEX Cache Throughput             %         98.75
    L2 Cache Throughput                 %          8.44
    SM Active Cycles                cycle 40,380,218.90
    Compute (SM) Throughput             %         10.98
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  2,048
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        99.13
    Achieved Active Warps Per SM           warp        31.72
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 2 512 1024 1024 gpu
CLI arguments: block_x = 2, block_y = 512, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 11824 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.812066 seconds.
==PROF== Disconnected from process 11824
[11824] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (512, 2, 1)x(2, 512, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.57
    SM Frequency            cycle/usecond        942.96
    Elapsed Cycles                  cycle    40,830,061
    Memory Throughput                   %         49.43
    DRAM Throughput                     %          0.14
    Duration                      msecond         43.29
    L1/TEX Cache Throughput             %         98.87
    L2 Cache Throughput                 %         16.51
    SM Active Cycles                cycle 40,282,417.43
    Compute (SM) Throughput             %         10.98
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,024
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            1
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.78
    Achieved Active Warps Per SM           warp        31.61
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 4 1 1024 1024 gpu
CLI arguments: block_x = 4, block_y = 1, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 11886 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 1.22871 seconds.
==PROF== Disconnected from process 11886
[11886] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (256, 1024, 1)x(4, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.69
    SM Frequency            cycle/usecond        959.38
    Elapsed Cycles                  cycle    90,367,401
    Memory Throughput                   %         49.57
    DRAM Throughput                     %         13.97
    Duration                      msecond         94.14
    L1/TEX Cache Throughput             %         99.13
    L2 Cache Throughput                 %          6.96
    SM Active Cycles                cycle 90,298,522.73
    Compute (SM) Throughput             %         39.69
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     4
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                262,144
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                              546.13
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 87.5%                                                                                           
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 4      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           40
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.92
    Achieved Active Warps Per SM           warp        15.97
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 4 2 1024 1024 gpu
CLI arguments: block_x = 4, block_y = 2, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 11945 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.932396 seconds.
==PROF== Disconnected from process 11945
[11945] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (256, 512, 1)x(4, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.52
    SM Frequency            cycle/usecond        935.55
    Elapsed Cycles                  cycle    53,814,452
    Memory Throughput                   %         49.93
    DRAM Throughput                     %         11.57
    Duration                      msecond         57.50
    L1/TEX Cache Throughput             %         99.86
    L2 Cache Throughput                 %          6.17
    SM Active Cycles                cycle 53,774,255.63
    Compute (SM) Throughput             %         33.31
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                131,072
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                              273.07
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 75%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           40
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.91
    Achieved Active Warps Per SM           warp        15.97
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 4 4 1024 1024 gpu
CLI arguments: block_x = 4, block_y = 4, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 12011 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.756232 seconds.
==PROF== Disconnected from process 12011
[12011] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (256, 256, 1)x(4, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.51
    SM Frequency            cycle/usecond        933.27
    Elapsed Cycles                  cycle    35,868,953
    Memory Throughput                   %         49.96
    DRAM Throughput                     %          8.66
    Duration                      msecond         38.41
    L1/TEX Cache Throughput             %         99.92
    L2 Cache Throughput                 %          5.16
    SM Active Cycles                cycle 35,819,662.87
    Compute (SM) Throughput             %         25.00
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 65,536
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                              136.53
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           40
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.86
    Achieved Active Warps Per SM           warp        15.96
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 4 8 1024 1024 gpu
CLI arguments: block_x = 4, block_y = 8, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 12086 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.650852 seconds.
==PROF== Disconnected from process 12086
[12086] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (256, 128, 1)x(4, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.51
    SM Frequency            cycle/usecond        934.36
    Elapsed Cycles                  cycle    26,922,560
    Memory Throughput                   %         49.92
    DRAM Throughput                     %          5.86
    Duration                      msecond         28.81
    L1/TEX Cache Throughput             %         99.85
    L2 Cache Throughput                 %          4.29
    SM Active Cycles                cycle 26,874,166.87
    Compute (SM) Throughput             %         16.65
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 32,768
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               68.27
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           40
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.72
    Achieved Active Warps Per SM           warp        15.91
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 4 16 1024 1024 gpu
CLI arguments: block_x = 4, block_y = 16, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 12148 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.677856 seconds.
==PROF== Disconnected from process 12148
[12148] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (256, 64, 1)x(4, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.52
    SM Frequency            cycle/usecond        934.79
    Elapsed Cycles                  cycle    26,925,928
    Memory Throughput                   %         49.91
    DRAM Throughput                     %          2.90
    Duration                      msecond         28.80
    L1/TEX Cache Throughput             %         99.82
    L2 Cache Throughput                 %          4.74
    SM Active Cycles                cycle 26,866,365.10
    Compute (SM) Throughput             %         16.64
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 16,384
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           20
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        97.29
    Achieved Active Warps Per SM           warp        31.13
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 4 32 1024 1024 gpu
CLI arguments: block_x = 4, block_y = 32, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 12207 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.716421 seconds.
==PROF== Disconnected from process 12207
[12207] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (256, 32, 1)x(4, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.52
    SM Frequency            cycle/usecond        935.35
    Elapsed Cycles                  cycle    26,928,816
    Memory Throughput                   %         49.91
    DRAM Throughput                     %          1.54
    Duration                      msecond         28.78
    L1/TEX Cache Throughput             %         99.82
    L2 Cache Throughput                 %          6.27
    SM Active Cycles                cycle 26,872,416.47
    Compute (SM) Throughput             %         16.64
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  8,192
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.66
    Achieved Active Warps Per SM           warp        31.57
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 4 64 1024 1024 gpu
CLI arguments: block_x = 4, block_y = 64, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 12260 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.684635 seconds.
==PROF== Disconnected from process 12260
[12260] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (256, 16, 1)x(4, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.53
    SM Frequency            cycle/usecond       936.72
    Elapsed Cycles                  cycle   26,973,510
    Memory Throughput                   %        49.82
    DRAM Throughput                     %         0.83
    Duration                      msecond        28.79
    L1/TEX Cache Throughput             %        99.65
    L2 Cache Throughput                 %         6.00
    SM Active Cycles                cycle   26,851,410
    Compute (SM) Throughput             %        16.61
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  4,096
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.81
    Achieved Active Warps Per SM           warp        31.62
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 4 128 1024 1024 gpu
CLI arguments: block_x = 4, block_y = 128, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 12310 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.694311 seconds.
==PROF== Disconnected from process 12310
[12310] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (256, 8, 1)x(4, 128, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.58
    SM Frequency            cycle/usecond        943.65
    Elapsed Cycles                  cycle    27,185,200
    Memory Throughput                   %         49.43
    DRAM Throughput                     %          0.46
    Duration                      msecond         28.80
    L1/TEX Cache Throughput             %         98.85
    L2 Cache Throughput                 %          6.10
    SM Active Cycles                cycle 26,882,027.83
    Compute (SM) Throughput             %         16.48
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  2,048
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        99.10
    Achieved Active Warps Per SM           warp        31.71
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 4 256 1024 1024 gpu
CLI arguments: block_x = 4, block_y = 256, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 12380 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.681953 seconds.
==PROF== Disconnected from process 12380
[12380] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (256, 4, 1)x(4, 256, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.59
    SM Frequency            cycle/usecond        945.15
    Elapsed Cycles                  cycle    27,557,121
    Memory Throughput                   %         48.76
    DRAM Throughput                     %          0.27
    Duration                      msecond         29.15
    L1/TEX Cache Throughput             %         97.53
    L2 Cache Throughput                 %          5.68
    SM Active Cycles                cycle 26,817,790.70
    Compute (SM) Throughput             %         16.26
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,024
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            1
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.65
    Achieved Active Warps Per SM           warp        31.57
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 8 1 1024 1024 gpu
CLI arguments: block_x = 8, block_y = 1, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 12446 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 1.14867 seconds.
==PROF== Disconnected from process 12446
[12446] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (128, 1024, 1)x(8, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.66
    SM Frequency            cycle/usecond        955.38
    Elapsed Cycles                  cycle    80,759,654
    Memory Throughput                   %         49.90
    DRAM Throughput                     %         14.90
    Duration                      msecond         84.51
    L1/TEX Cache Throughput             %         99.81
    L2 Cache Throughput                 %          7.73
    SM Active Cycles                cycle 80,711,556.80
    Compute (SM) Throughput             %         22.20
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                     8
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                131,072
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                              273.07
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 75%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 8      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           40
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.92
    Achieved Active Warps Per SM           warp        15.97
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 8 2 1024 1024 gpu
CLI arguments: block_x = 8, block_y = 2, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 12518 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.825994 seconds.
==PROF== Disconnected from process 12518
[12518] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (128, 512, 1)x(8, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.51
    SM Frequency            cycle/usecond        933.62
    Elapsed Cycles                  cycle    44,817,727
    Memory Throughput                   %         49.96
    DRAM Throughput                     %         13.17
    Duration                      msecond         47.99
    L1/TEX Cache Throughput             %         99.92
    L2 Cache Throughput                 %          7.24
    SM Active Cycles                cycle 44,776,046.47
    Compute (SM) Throughput             %         20.00
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 65,536
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                              136.53
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           40
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.86
    Achieved Active Warps Per SM           warp        15.95
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 8 4 1024 1024 gpu
CLI arguments: block_x = 8, block_y = 4, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 12574 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.684411 seconds.
==PROF== Disconnected from process 12574
[12574] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (128, 256, 1)x(8, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.51
    SM Frequency            cycle/usecond        934.68
    Elapsed Cycles                  cycle    26,904,156
    Memory Throughput                   %         49.94
    DRAM Throughput                     %         11.02
    Duration                      msecond         28.78
    L1/TEX Cache Throughput             %         99.87
    L2 Cache Throughput                 %          6.46
    SM Active Cycles                cycle 26,864,742.37
    Compute (SM) Throughput             %         16.66
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 32,768
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               68.27
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           40
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.74
    Achieved Active Warps Per SM           warp        15.92
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 8 8 1024 1024 gpu
CLI arguments: block_x = 8, block_y = 8, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 12627 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.65985 seconds.
==PROF== Disconnected from process 12627
[12627] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (128, 128, 1)x(8, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.52
    SM Frequency            cycle/usecond        935.38
    Elapsed Cycles                  cycle    26,920,041
    Memory Throughput                   %         49.90
    DRAM Throughput                     %          4.70
    Duration                      msecond         28.78
    L1/TEX Cache Throughput             %         99.80
    L2 Cache Throughput                 %          5.51
    SM Active Cycles                cycle 26,862,077.63
    Compute (SM) Throughput             %         16.65
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 16,384
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           20
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        97.07
    Achieved Active Warps Per SM           warp        31.06
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 8 16 1024 1024 gpu
CLI arguments: block_x = 8, block_y = 16, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 12702 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.71196 seconds.
==PROF== Disconnected from process 12702
[12702] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (128, 64, 1)x(8, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.52
    SM Frequency            cycle/usecond        935.65
    Elapsed Cycles                  cycle    26,919,588
    Memory Throughput                   %         49.91
    DRAM Throughput                     %          2.97
    Duration                      msecond         28.76
    L1/TEX Cache Throughput             %         99.81
    L2 Cache Throughput                 %          4.16
    SM Active Cycles                cycle 26,858,525.93
    Compute (SM) Throughput             %         16.65
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  8,192
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.65
    Achieved Active Warps Per SM           warp        31.57
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 8 32 1024 1024 gpu
CLI arguments: block_x = 8, block_y = 32, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 12763 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.667743 seconds.
==PROF== Disconnected from process 12763
[12763] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (128, 32, 1)x(8, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.53
    SM Frequency            cycle/usecond        936.71
    Elapsed Cycles                  cycle    26,954,482
    Memory Throughput                   %         49.83
    DRAM Throughput                     %          1.54
    Duration                      msecond         28.77
    L1/TEX Cache Throughput             %         99.67
    L2 Cache Throughput                 %          3.45
    SM Active Cycles                cycle 26,817,428.07
    Compute (SM) Throughput             %         16.63
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  4,096
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.88
    Achieved Active Warps Per SM           warp        31.64
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 8 64 1024 1024 gpu
CLI arguments: block_x = 8, block_y = 64, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 12820 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.707353 seconds.
==PROF== Disconnected from process 12820
[12820] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (128, 16, 1)x(8, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.57
    SM Frequency            cycle/usecond        943.33
    Elapsed Cycles                  cycle    27,150,014
    Memory Throughput                   %         49.47
    DRAM Throughput                     %          0.83
    Duration                      msecond         28.78
    L1/TEX Cache Throughput             %         98.94
    L2 Cache Throughput                 %          3.10
    SM Active Cycles                cycle 26,807,760.17
    Compute (SM) Throughput             %         16.51
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  2,048
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        99.17
    Achieved Active Warps Per SM           warp        31.73
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 8 128 1024 1024 gpu
CLI arguments: block_x = 8, block_y = 128, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 12876 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.71717 seconds.
==PROF== Disconnected from process 12876
[12876] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (128, 8, 1)x(8, 128, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.58
    SM Frequency            cycle/usecond        944.39
    Elapsed Cycles                  cycle    27,559,317
    Memory Throughput                   %         48.74
    DRAM Throughput                     %          0.45
    Duration                      msecond         29.18
    L1/TEX Cache Throughput             %         97.47
    L2 Cache Throughput                 %          2.89
    SM Active Cycles                cycle 26,843,498.13
    Compute (SM) Throughput             %         16.26
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,024
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            1
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.69
    Achieved Active Warps Per SM           warp        31.58
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 16 1 1024 1024 gpu
CLI arguments: block_x = 16, block_y = 1, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 13149 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 1.1245 seconds.
==PROF== Disconnected from process 13149
[13149] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (64, 1024, 1)x(16, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.64
    SM Frequency            cycle/usecond        952.70
    Elapsed Cycles                  cycle    76,192,726
    Memory Throughput                   %         49.94
    DRAM Throughput                     %          8.22
    Duration                      msecond         79.96
    L1/TEX Cache Throughput             %         99.88
    L2 Cache Throughput                 %          8.74
    SM Active Cycles                cycle 76,142,365.50
    Compute (SM) Throughput             %         11.76
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    16
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 65,536
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                              136.53
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 50%                                                                                             
          Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           40
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.86
    Achieved Active Warps Per SM           warp        15.96
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 16 2 1024 1024 gpu
CLI arguments: block_x = 16, block_y = 2, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 13589 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.800481 seconds.
==PROF== Disconnected from process 13589
[13589] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (64, 512, 1)x(16, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.51
    SM Frequency            cycle/usecond        934.27
    Elapsed Cycles                  cycle    40,342,944
    Memory Throughput                   %         49.94
    DRAM Throughput                     %          7.85
    Duration                      msecond         43.17
    L1/TEX Cache Throughput             %         99.87
    L2 Cache Throughput                 %          8.47
    SM Active Cycles                cycle 40,287,745.10
    Compute (SM) Throughput             %         11.11
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 32,768
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               68.27
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           40
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.75
    Achieved Active Warps Per SM           warp        15.92
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 16 4 1024 1024 gpu
CLI arguments: block_x = 16, block_y = 4, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 13668 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.7859 seconds.
==PROF== Disconnected from process 13668
[13668] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (64, 256, 1)x(16, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.50
    SM Frequency            cycle/usecond        932.57
    Elapsed Cycles                  cycle    40,363,923
    Memory Throughput                   %         49.92
    DRAM Throughput                     %          6.83
    Duration                      msecond         43.27
    L1/TEX Cache Throughput             %         99.84
    L2 Cache Throughput                 %          5.86
    SM Active Cycles                cycle 40,292,636.30
    Compute (SM) Throughput             %         11.10
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 16,384
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           20
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        97.62
    Achieved Active Warps Per SM           warp        31.24
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 16 8 1024 1024 gpu
CLI arguments: block_x = 16, block_y = 8, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 13741 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.793761 seconds.
==PROF== Disconnected from process 13741
[13741] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (64, 128, 1)x(16, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.52
    SM Frequency            cycle/usecond        935.03
    Elapsed Cycles                  cycle    40,351,285
    Memory Throughput                   %         49.92
    DRAM Throughput                     %          3.81
    Duration                      msecond         43.15
    L1/TEX Cache Throughput             %         99.84
    L2 Cache Throughput                 %          2.87
    SM Active Cycles                cycle 40,276,375.10
    Compute (SM) Throughput             %         11.11
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  8,192
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.67
    Achieved Active Warps Per SM           warp        31.57
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 16 16 1024 1024 gpu
CLI arguments: block_x = 16, block_y = 16, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 13806 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.826816 seconds.
==PROF== Disconnected from process 13806
[13806] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (64, 64, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.53
    SM Frequency            cycle/usecond        936.70
    Elapsed Cycles                  cycle    40,424,011
    Memory Throughput                   %         49.83
    DRAM Throughput                     %          1.98
    Duration                      msecond         43.15
    L1/TEX Cache Throughput             %         99.66
    L2 Cache Throughput                 %          1.86
    SM Active Cycles                cycle 40,257,144.93
    Compute (SM) Throughput             %         11.09
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  4,096
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.83
    Achieved Active Warps Per SM           warp        31.62
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 16 32 1024 1024 gpu
CLI arguments: block_x = 16, block_y = 32, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 13863 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.812342 seconds.
==PROF== Disconnected from process 13863
[13863] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (64, 32, 1)x(16, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.57
    SM Frequency            cycle/usecond        943.40
    Elapsed Cycles                  cycle    40,712,695
    Memory Throughput                   %         49.47
    DRAM Throughput                     %          1.02
    Duration                      msecond         43.15
    L1/TEX Cache Throughput             %         98.94
    L2 Cache Throughput                 %          1.38
    SM Active Cycles                cycle 40,258,145.30
    Compute (SM) Throughput             %         11.01
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  2,048
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        99.14
    Achieved Active Warps Per SM           warp        31.73
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 16 64 1024 1024 gpu
CLI arguments: block_x = 16, block_y = 64, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 13942 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.804181 seconds.
==PROF== Disconnected from process 13942
[13942] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (64, 16, 1)x(16, 64, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.58
    SM Frequency            cycle/usecond        944.15
    Elapsed Cycles                  cycle    41,324,784
    Memory Throughput                   %         48.73
    DRAM Throughput                     %          0.55
    Duration                      msecond         43.77
    L1/TEX Cache Throughput             %         97.47
    L2 Cache Throughput                 %          1.14
    SM Active Cycles                cycle 40,294,196.50
    Compute (SM) Throughput             %         10.84
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,024
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            1
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.76
    Achieved Active Warps Per SM           warp        31.60
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 32 1 1024 1024 gpu
CLI arguments: block_x = 32, block_y = 1, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 14022 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 1.05105 seconds.
==PROF== Disconnected from process 14022
[14022] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (32, 1024, 1)x(32, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.65
    SM Frequency            cycle/usecond        954.48
    Elapsed Cycles                  cycle    74,160,324
    Memory Throughput                   %         49.81
    DRAM Throughput                     %          4.19
    Duration                      msecond         77.67
    L1/TEX Cache Throughput             %         99.62
    L2 Cache Throughput                 %         13.54
    SM Active Cycles                cycle 74,028,102.13
    Compute (SM) Throughput             %          6.04
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 32,768
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               68.27
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           40
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           16
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %        49.78
    Achieved Active Warps Per SM           warp        15.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 50%                                                                                       
          The 4.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the       
          hardware maximum of 8. This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that    
          can fit on the SM. This kernel's theoretical occupancy (50.0%) is limited by the required amount of shared    
          memory.                                                                                                       

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 32 2 1024 1024 gpu
CLI arguments: block_x = 32, block_y = 2, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 14096 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 1.05161 seconds.
==PROF== Disconnected from process 14096
[14096] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (32, 512, 1)x(32, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.65
    SM Frequency            cycle/usecond        954.40
    Elapsed Cycles                  cycle    74,258,914
    Memory Throughput                   %         49.73
    DRAM Throughput                     %          4.89
    Duration                      msecond         77.79
    L1/TEX Cache Throughput             %         99.47
    L2 Cache Throughput                 %          9.35
    SM Active Cycles                cycle 74,075,601.27
    Compute (SM) Throughput             %          6.04
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 16,384
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           20
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        97.30
    Achieved Active Warps Per SM           warp        31.14
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 32 4 1024 1024 gpu
CLI arguments: block_x = 32, block_y = 4, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 14164 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 1.04192 seconds.
==PROF== Disconnected from process 14164
[14164] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (32, 256, 1)x(32, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.61
    SM Frequency            cycle/usecond        948.11
    Elapsed Cycles                  cycle    73,979,634
    Memory Throughput                   %         49.91
    DRAM Throughput                     %          3.76
    Duration                      msecond         78.02
    L1/TEX Cache Throughput             %         99.82
    L2 Cache Throughput                 %          2.66
    SM Active Cycles                cycle 73,834,566.60
    Compute (SM) Throughput             %          6.06
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  8,192
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.69
    Achieved Active Warps Per SM           warp        31.58
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 32 8 1024 1024 gpu
CLI arguments: block_x = 32, block_y = 8, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 14247 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 1.08015 seconds.
==PROF== Disconnected from process 14247
[14247] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (32, 128, 1)x(32, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.63
    SM Frequency            cycle/usecond        950.84
    Elapsed Cycles                  cycle    74,096,173
    Memory Throughput                   %         49.82
    DRAM Throughput                     %          2.03
    Duration                      msecond         77.92
    L1/TEX Cache Throughput             %         99.65
    L2 Cache Throughput                 %          1.28
    SM Active Cycles                cycle 73,763,452.10
    Compute (SM) Throughput             %          6.05
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  4,096
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.91
    Achieved Active Warps Per SM           warp        31.65
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 32 16 1024 1024 gpu
CLI arguments: block_x = 32, block_y = 16, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 14347 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 1.05842 seconds.
==PROF== Disconnected from process 14347
[14347] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (32, 64, 1)x(32, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.66
    SM Frequency            cycle/usecond        955.68
    Elapsed Cycles                  cycle    74,627,859
    Memory Throughput                   %         49.47
    DRAM Throughput                     %          1.08
    Duration                      msecond         78.08
    L1/TEX Cache Throughput             %         98.94
    L2 Cache Throughput                 %          0.76
    SM Active Cycles                cycle 73,797,356.87
    Compute (SM) Throughput             %          6.00
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  2,048
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        99.18
    Achieved Active Warps Per SM           warp        31.74
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 32 32 1024 1024 gpu
CLI arguments: block_x = 32, block_y = 32, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 14414 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 1.07757 seconds.
==PROF== Disconnected from process 14414
[14414] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (32, 32, 1)x(32, 32, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.66
    SM Frequency            cycle/usecond        955.61
    Elapsed Cycles                  cycle    75,726,584
    Memory Throughput                   %         48.75
    DRAM Throughput                     %          0.58
    Duration                      msecond         79.24
    L1/TEX Cache Throughput             %         97.50
    L2 Cache Throughput                 %          0.50
    SM Active Cycles                cycle 73,844,294.23
    Compute (SM) Throughput             %          5.92
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,024
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            1
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.79
    Achieved Active Warps Per SM           warp        31.61
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 64 1 1024 1024 gpu
CLI arguments: block_x = 64, block_y = 1, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 14470 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 1.05603 seconds.
==PROF== Disconnected from process 14470
[14470] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (16, 1024, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.64
    SM Frequency            cycle/usecond        952.52
    Elapsed Cycles                  cycle    74,510,017
    Memory Throughput                   %         49.59
    DRAM Throughput                     %          5.01
    Duration                      msecond         78.17
    L1/TEX Cache Throughput             %         99.18
    L2 Cache Throughput                 %         15.48
    SM Active Cycles                cycle 74,281,042.87
    Compute (SM) Throughput             %          6.02
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                 16,384
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           20
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        97.13
    Achieved Active Warps Per SM           warp        31.08
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 64 2 1024 1024 gpu
CLI arguments: block_x = 64, block_y = 2, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 14559 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 1.06628 seconds.
==PROF== Disconnected from process 14559
[14559] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (16, 512, 1)x(64, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.66
    SM Frequency            cycle/usecond        955.45
    Elapsed Cycles                  cycle    74,234,183
    Memory Throughput                   %         49.74
    DRAM Throughput                     %          3.95
    Duration                      msecond         77.68
    L1/TEX Cache Throughput             %         99.49
    L2 Cache Throughput                 %          6.55
    SM Active Cycles                cycle 74,078,137.70
    Compute (SM) Throughput             %          6.04
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  8,192
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.74
    Achieved Active Warps Per SM           warp        31.60
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 64 4 1024 1024 gpu
CLI arguments: block_x = 64, block_y = 4, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 14656 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 1.06221 seconds.
==PROF== Disconnected from process 14656
[14656] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (16, 256, 1)x(64, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.62
    SM Frequency            cycle/usecond        950.50
    Elapsed Cycles                  cycle    74,107,651
    Memory Throughput                   %         49.82
    DRAM Throughput                     %          2.11
    Duration                      msecond         77.96
    L1/TEX Cache Throughput             %         99.63
    L2 Cache Throughput                 %          2.40
    SM Active Cycles                cycle 73,776,082.70
    Compute (SM) Throughput             %          6.05
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  4,096
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.90
    Achieved Active Warps Per SM           warp        31.65
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 64 8 1024 1024 gpu
CLI arguments: block_x = 64, block_y = 8, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 14718 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 1.12077 seconds.
==PROF== Disconnected from process 14718
[14718] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (16, 128, 1)x(64, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.65
    SM Frequency            cycle/usecond        954.61
    Elapsed Cycles                  cycle    74,628,884
    Memory Throughput                   %         49.47
    DRAM Throughput                     %          1.13
    Duration                      msecond         78.17
    L1/TEX Cache Throughput             %         98.94
    L2 Cache Throughput                 %          1.13
    SM Active Cycles                cycle 73,798,193.07
    Compute (SM) Throughput             %          6.00
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  2,048
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        99.19
    Achieved Active Warps Per SM           warp        31.74
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 64 16 1024 1024 gpu
CLI arguments: block_x = 64, block_y = 16, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 14774 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 1.09935 seconds.
==PROF== Disconnected from process 14774
[14774] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (16, 64, 1)x(64, 16, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.67
    SM Frequency            cycle/usecond        957.14
    Elapsed Cycles                  cycle    75,706,194
    Memory Throughput                   %         48.76
    DRAM Throughput                     %          0.61
    Duration                      msecond         79.09
    L1/TEX Cache Throughput             %         97.53
    L2 Cache Throughput                 %          0.63
    SM Active Cycles                cycle 73,761,885.50
    Compute (SM) Throughput             %          5.92
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,024
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            1
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.79
    Achieved Active Warps Per SM           warp        31.61
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 128 1 1024 1024 gpu
CLI arguments: block_x = 128, block_y = 1, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 14860 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 1.06692 seconds.
==PROF== Disconnected from process 14860
[14860] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (8, 1024, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.62
    SM Frequency            cycle/usecond        949.70
    Elapsed Cycles                  cycle    74,442,470
    Memory Throughput                   %         49.63
    DRAM Throughput                     %          4.23
    Duration                      msecond         78.34
    L1/TEX Cache Throughput             %         99.26
    L2 Cache Throughput                 %         14.41
    SM Active Cycles                cycle 74,291,246.80
    Compute (SM) Throughput             %          6.02
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  8,192
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.78
    Achieved Active Warps Per SM           warp        31.61
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 128 2 1024 1024 gpu
CLI arguments: block_x = 128, block_y = 2, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 14958 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 1.06689 seconds.
==PROF== Disconnected from process 14958
[14958] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (8, 512, 1)x(128, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.63
    SM Frequency            cycle/usecond        950.87
    Elapsed Cycles                  cycle    74,391,770
    Memory Throughput                   %         49.64
    DRAM Throughput                     %          2.06
    Duration                      msecond         78.21
    L1/TEX Cache Throughput             %         99.28
    L2 Cache Throughput                 %          6.20
    SM Active Cycles                cycle 74,057,501.17
    Compute (SM) Throughput             %          6.02
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  4,096
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.90
    Achieved Active Warps Per SM           warp        31.65
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 128 4 1024 1024 gpu
CLI arguments: block_x = 128, block_y = 4, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 15020 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 1.06269 seconds.
==PROF== Disconnected from process 15020
[15020] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (8, 256, 1)x(128, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.66
    SM Frequency            cycle/usecond        955.05
    Elapsed Cycles                  cycle    74,632,219
    Memory Throughput                   %         49.47
    DRAM Throughput                     %          1.14
    Duration                      msecond         78.13
    L1/TEX Cache Throughput             %         98.94
    L2 Cache Throughput                 %          2.15
    SM Active Cycles                cycle 73,697,188.67
    Compute (SM) Throughput             %          6.00
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  2,048
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        99.26
    Achieved Active Warps Per SM           warp        31.76
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 128 8 1024 1024 gpu
CLI arguments: block_x = 128, block_y = 8, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 15077 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 1.07186 seconds.
==PROF== Disconnected from process 15077
[15077] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (8, 128, 1)x(128, 8, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.65
    SM Frequency            cycle/usecond        954.62
    Elapsed Cycles                  cycle    74,675,998
    Memory Throughput                   %         49.44
    DRAM Throughput                     %          0.61
    Duration                      msecond         78.21
    L1/TEX Cache Throughput             %         98.89
    L2 Cache Throughput                 %          1.30
    SM Active Cycles                cycle 73,687,772.40
    Compute (SM) Throughput             %          6.00
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,024
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            1
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.79
    Achieved Active Warps Per SM           warp        31.61
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 256 1 1024 1024 gpu
CLI arguments: block_x = 256, block_y = 1, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 15163 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 1.06514 seconds.
==PROF== Disconnected from process 15163
[15163] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (4, 1024, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.66
    SM Frequency            cycle/usecond        955.47
    Elapsed Cycles                  cycle    74,582,926
    Memory Throughput                   %         49.55
    DRAM Throughput                     %          2.08
    Duration                      msecond         77.99
    L1/TEX Cache Throughput             %         99.11
    L2 Cache Throughput                 %         15.06
    SM Active Cycles                cycle 74,231,811.43
    Compute (SM) Throughput             %          6.01
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  4,096
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.88
    Achieved Active Warps Per SM           warp        31.64
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 256 2 1024 1024 gpu
CLI arguments: block_x = 256, block_y = 2, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 15261 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 1.07353 seconds.
==PROF== Disconnected from process 15261
[15261] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (4, 512, 1)x(256, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.61
    SM Frequency            cycle/usecond        948.79
    Elapsed Cycles                  cycle    74,380,251
    Memory Throughput                   %         49.66
    DRAM Throughput                     %          1.13
    Duration                      msecond         78.36
    L1/TEX Cache Throughput             %         99.32
    L2 Cache Throughput                 %          6.91
    SM Active Cycles                cycle 73,909,147.37
    Compute (SM) Throughput             %          6.03
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  2,048
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        99.23
    Achieved Active Warps Per SM           warp        31.75
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 256 4 1024 1024 gpu
CLI arguments: block_x = 256, block_y = 4, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 15323 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 1.09968 seconds.
==PROF== Disconnected from process 15323
[15323] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (4, 256, 1)x(256, 4, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.64
    SM Frequency            cycle/usecond        951.53
    Elapsed Cycles                  cycle    75,088,081
    Memory Throughput                   %         49.28
    DRAM Throughput                     %          0.62
    Duration                      msecond         78.85
    L1/TEX Cache Throughput             %         98.55
    L2 Cache Throughput                 %         17.46
    SM Active Cycles                cycle 74,003,731.83
    Compute (SM) Throughput             %          5.97
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,024
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            1
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.75
    Achieved Active Warps Per SM           warp        31.60
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 512 1 1024 1024 gpu
CLI arguments: block_x = 512, block_y = 1, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 15379 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 1.08562 seconds.
==PROF== Disconnected from process 15379
[15379] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (2, 1024, 1)x(512, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.66
    SM Frequency            cycle/usecond        954.42
    Elapsed Cycles                  cycle    75,128,835
    Memory Throughput                   %         49.25
    DRAM Throughput                     %          1.13
    Duration                      msecond         78.64
    L1/TEX Cache Throughput             %         98.50
    L2 Cache Throughput                 %         19.78
    SM Active Cycles                cycle 74,210,978.37
    Compute (SM) Throughput             %          5.97
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  2,048
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        99.19
    Achieved Active Warps Per SM           warp        31.74
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 512 2 1024 1024 gpu
CLI arguments: block_x = 512, block_y = 2, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 15482 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 1.07427 seconds.
==PROF== Disconnected from process 15482
[15482] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (2, 512, 1)x(512, 2, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.65
    SM Frequency            cycle/usecond        954.20
    Elapsed Cycles                  cycle    76,024,476
    Memory Throughput                   %         48.72
    DRAM Throughput                     %          0.61
    Duration                      msecond         79.67
    L1/TEX Cache Throughput             %         97.43
    L2 Cache Throughput                 %         40.13
    SM Active Cycles                cycle 74,953,998.63
    Compute (SM) Throughput             %          5.89
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,024
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            1
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.70
    Achieved Active Warps Per SM           warp        31.58
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: compute_attention_scores in directory: ./attention/build with args: 1024 1 1024 1024 gpu
CLI arguments: block_x = 1024, block_y = 1, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 15555 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "compute_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 1.09011 seconds.
==PROF== Disconnected from process 15555
[15555] attention_solver@127.0.0.1
  compute_attention_scores(float *, float *, float *, int, int) (1, 1024, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- -------------
    Metric Name               Metric Unit  Metric Value
    ----------------------- ------------- -------------
    DRAM Frequency          cycle/nsecond          6.56
    SM Frequency            cycle/usecond        941.01
    Elapsed Cycles                  cycle    75,557,624
    Memory Throughput                   %         55.10
    DRAM Throughput                     %          0.62
    Duration                      msecond         80.29
    L1/TEX Cache Throughput             %         98.08
    L2 Cache Throughput                 %         55.10
    SM Active Cycles                cycle 74,457,744.80
    Compute (SM) Throughput             %          5.93
    ----------------------- ------------- -------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,024
    Registers Per Thread             register/thread              45
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                               34.13
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            1
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            1
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        98.81
    Achieved Active Warps Per SM           warp        31.62
    ------------------------------- ----------- ------------

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 1 1 1024 1024 gpu
CLI arguments: block_x = 1, block_y = 1, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 15617 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.71421 seconds.
==PROF== Disconnected from process 15617
[15617] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.72
    SM Frequency            cycle/usecond       926.45
    Elapsed Cycles                  cycle    1,914,731
    Memory Throughput                   %        10.80
    DRAM Throughput                     %         2.98
    Duration                      msecond         2.04
    L1/TEX Cache Throughput             %        72.72
    L2 Cache Throughput                 %        10.80
    SM Active Cycles                cycle   245,418.40
    Compute (SM) Throughput             %         2.26
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.79
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.21%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 1 2 1024 1024 gpu
CLI arguments: block_x = 1, block_y = 2, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 15667 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.59184 seconds.
==PROF== Disconnected from process 15667
[15667] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.80
    SM Frequency            cycle/usecond       937.26
    Elapsed Cycles                  cycle    1,901,709
    Memory Throughput                   %        10.85
    DRAM Throughput                     %         3.00
    Duration                      msecond         2.00
    L1/TEX Cache Throughput             %        72.60
    L2 Cache Throughput                 %        10.85
    SM Active Cycles                cycle   245,775.27
    Compute (SM) Throughput             %         2.27
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.79
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.21%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 1 4 1024 1024 gpu
CLI arguments: block_x = 1, block_y = 4, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 15750 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.570747 seconds.
==PROF== Disconnected from process 15750
[15750] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.57
    SM Frequency            cycle/usecond       905.04
    Elapsed Cycles                  cycle    1,875,365
    Memory Throughput                   %        11.02
    DRAM Throughput                     %         3.05
    Duration                      msecond         2.05
    L1/TEX Cache Throughput             %        72.97
    L2 Cache Throughput                 %        11.02
    SM Active Cycles                cycle   244,366.30
    Compute (SM) Throughput             %         2.30
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.79
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.21%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 1 8 1024 1024 gpu
CLI arguments: block_x = 1, block_y = 8, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 15819 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.556167 seconds.
==PROF== Disconnected from process 15819
[15819] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.71
    SM Frequency            cycle/usecond       924.43
    Elapsed Cycles                  cycle    1,869,921
    Memory Throughput                   %        11.06
    DRAM Throughput                     %         3.05
    Duration                      msecond         2.00
    L1/TEX Cache Throughput             %        72.98
    L2 Cache Throughput                 %        11.06
    SM Active Cycles                cycle   244,564.97
    Compute (SM) Throughput             %         2.31
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.81
    Achieved Active Warps Per SM           warp         7.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.19%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 1 16 1024 1024 gpu
CLI arguments: block_x = 1, block_y = 16, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 15879 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.631049 seconds.
==PROF== Disconnected from process 15879
[15879] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.82
    SM Frequency            cycle/usecond       938.98
    Elapsed Cycles                  cycle    1,906,361
    Memory Throughput                   %        10.82
    DRAM Throughput                     %         3.00
    Duration                      msecond         2.01
    L1/TEX Cache Throughput             %        72.47
    L2 Cache Throughput                 %        10.82
    SM Active Cycles                cycle   246,462.87
    Compute (SM) Throughput             %         2.26
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.79
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.21%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 1 32 1024 1024 gpu
CLI arguments: block_x = 1, block_y = 32, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 15938 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.586198 seconds.
==PROF== Disconnected from process 15938
[15938] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.71
    SM Frequency            cycle/usecond       923.30
    Elapsed Cycles                  cycle    1,879,579
    Memory Throughput                   %        10.96
    DRAM Throughput                     %         3.02
    Duration                      msecond         2.02
    L1/TEX Cache Throughput             %        72.74
    L2 Cache Throughput                 %        10.96
    SM Active Cycles                cycle   245,381.87
    Compute (SM) Throughput             %         2.29
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.79
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.21%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 1 64 1024 1024 gpu
CLI arguments: block_x = 1, block_y = 64, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 15994 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.620949 seconds.
==PROF== Disconnected from process 15994
[15994] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.76
    SM Frequency            cycle/usecond       929.66
    Elapsed Cycles                  cycle    1,894,142
    Memory Throughput                   %        10.83
    DRAM Throughput                     %         3.00
    Duration                      msecond         2.02
    L1/TEX Cache Throughput             %        72.87
    L2 Cache Throughput                 %        10.83
    SM Active Cycles                cycle   244,724.97
    Compute (SM) Throughput             %         2.27
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.83
    Achieved Active Warps Per SM           warp         7.95
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.17%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 1 128 1024 1024 gpu
CLI arguments: block_x = 1, block_y = 128, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 16044 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.570156 seconds.
==PROF== Disconnected from process 16044
[16044] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.79
    SM Frequency            cycle/usecond       934.68
    Elapsed Cycles                  cycle    1,900,395
    Memory Throughput                   %        10.84
    DRAM Throughput                     %         2.99
    Duration                      msecond         2.01
    L1/TEX Cache Throughput             %        72.53
    L2 Cache Throughput                 %        10.84
    SM Active Cycles                cycle   246,369.73
    Compute (SM) Throughput             %         2.27
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.81
    Achieved Active Warps Per SM           warp         7.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.19%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 1 256 1024 1024 gpu
CLI arguments: block_x = 1, block_y = 256, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 16117 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.633102 seconds.
==PROF== Disconnected from process 16117
[16117] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.75
    SM Frequency            cycle/usecond       930.88
    Elapsed Cycles                  cycle    1,891,536
    Memory Throughput                   %        10.92
    DRAM Throughput                     %         3.02
    Duration                      msecond         2.01
    L1/TEX Cache Throughput             %        72.00
    L2 Cache Throughput                 %        10.92
    SM Active Cycles                cycle   247,894.03
    Compute (SM) Throughput             %         2.28
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.79
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.21%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 1 512 1024 1024 gpu
CLI arguments: block_x = 1, block_y = 512, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 16194 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.589235 seconds.
==PROF== Disconnected from process 16194
[16194] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.66
    SM Frequency            cycle/usecond       916.78
    Elapsed Cycles                  cycle    1,874,450
    Memory Throughput                   %        11.03
    DRAM Throughput                     %         3.04
    Duration                      msecond         2.02
    L1/TEX Cache Throughput             %        72.30
    L2 Cache Throughput                 %        11.03
    SM Active Cycles                cycle   247,079.27
    Compute (SM) Throughput             %         2.30
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.78
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.22%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 1 1024 1024 1024 gpu
CLI arguments: block_x = 1, block_y = 1024, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 16254 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.59143 seconds.
==PROF== Disconnected from process 16254
[16254] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.75
    SM Frequency            cycle/usecond       930.03
    Elapsed Cycles                  cycle    1,884,313
    Memory Throughput                   %        10.96
    DRAM Throughput                     %         3.03
    Duration                      msecond         2.00
    L1/TEX Cache Throughput             %        72.68
    L2 Cache Throughput                 %        10.96
    SM Active Cycles                cycle   245,746.37
    Compute (SM) Throughput             %         2.29
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.81
    Achieved Active Warps Per SM           warp         7.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.19%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 2 1 1024 1024 gpu
CLI arguments: block_x = 2, block_y = 1, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 16311 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.619223 seconds.
==PROF== Disconnected from process 16311
[16311] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.74
    SM Frequency            cycle/usecond       926.70
    Elapsed Cycles                  cycle    1,888,837
    Memory Throughput                   %        10.88
    DRAM Throughput                     %         3.01
    Duration                      msecond         2.02
    L1/TEX Cache Throughput             %        72.30
    L2 Cache Throughput                 %        10.88
    SM Active Cycles                cycle   246,999.63
    Compute (SM) Throughput             %         2.28
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.78
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.22%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 2 2 1024 1024 gpu
CLI arguments: block_x = 2, block_y = 2, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 16364 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.554038 seconds.
==PROF== Disconnected from process 16364
[16364] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.90
    SM Frequency            cycle/usecond       948.48
    Elapsed Cycles                  cycle    1,911,320
    Memory Throughput                   %        10.78
    DRAM Throughput                     %         2.97
    Duration                      msecond         2.00
    L1/TEX Cache Throughput             %        72.41
    L2 Cache Throughput                 %        10.78
    SM Active Cycles                cycle   246,858.63
    Compute (SM) Throughput             %         2.25
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.82
    Achieved Active Warps Per SM           warp         7.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.18%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 2 4 1024 1024 gpu
CLI arguments: block_x = 2, block_y = 4, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 16414 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.537027 seconds.
==PROF== Disconnected from process 16414
[16414] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.74
    SM Frequency            cycle/usecond       927.59
    Elapsed Cycles                  cycle    1,889,757
    Memory Throughput                   %        10.94
    DRAM Throughput                     %         3.01
    Duration                      msecond         2.02
    L1/TEX Cache Throughput             %        72.98
    L2 Cache Throughput                 %        10.94
    SM Active Cycles                cycle   244,652.47
    Compute (SM) Throughput             %         2.28
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.78
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.22%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 2 8 1024 1024 gpu
CLI arguments: block_x = 2, block_y = 8, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 16465 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.538197 seconds.
==PROF== Disconnected from process 16465
[16465] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.77
    SM Frequency            cycle/usecond       930.82
    Elapsed Cycles                  cycle    1,885,117
    Memory Throughput                   %        10.89
    DRAM Throughput                     %         3.01
    Duration                      msecond         2.01
    L1/TEX Cache Throughput             %        71.90
    L2 Cache Throughput                 %        10.89
    SM Active Cycles                cycle   248,088.87
    Compute (SM) Throughput             %         2.28
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.82
    Achieved Active Warps Per SM           warp         7.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.18%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 2 16 1024 1024 gpu
CLI arguments: block_x = 2, block_y = 16, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 16541 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.551446 seconds.
==PROF== Disconnected from process 16541
[16541] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.75
    SM Frequency            cycle/usecond       929.68
    Elapsed Cycles                  cycle    1,905,619
    Memory Throughput                   %        10.81
    DRAM Throughput                     %         2.99
    Duration                      msecond         2.03
    L1/TEX Cache Throughput             %        72.49
    L2 Cache Throughput                 %        10.81
    SM Active Cycles                cycle   246,418.80
    Compute (SM) Throughput             %         2.26
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.79
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.21%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 2 32 1024 1024 gpu
CLI arguments: block_x = 2, block_y = 32, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 16620 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.562065 seconds.
==PROF== Disconnected from process 16620
[16620] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.71
    SM Frequency            cycle/usecond       924.26
    Elapsed Cycles                  cycle    1,872,020
    Memory Throughput                   %        10.97
    DRAM Throughput                     %         3.04
    Duration                      msecond         2.01
    L1/TEX Cache Throughput             %        72.25
    L2 Cache Throughput                 %        10.97
    SM Active Cycles                cycle   246,964.47
    Compute (SM) Throughput             %         2.30
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.79
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.21%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 2 64 1024 1024 gpu
CLI arguments: block_x = 2, block_y = 64, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 16680 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.573501 seconds.
==PROF== Disconnected from process 16680
[16680] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.63
    SM Frequency            cycle/usecond       913.82
    Elapsed Cycles                  cycle    1,887,209
    Memory Throughput                   %        10.98
    DRAM Throughput                     %         3.03
    Duration                      msecond         2.04
    L1/TEX Cache Throughput             %        72.00
    L2 Cache Throughput                 %        10.98
    SM Active Cycles                cycle   247,589.10
    Compute (SM) Throughput             %         2.29
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.80
    Achieved Active Warps Per SM           warp         7.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.2%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 2 128 1024 1024 gpu
CLI arguments: block_x = 2, block_y = 128, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 16730 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.544794 seconds.
==PROF== Disconnected from process 16730
[16730] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.71
    SM Frequency            cycle/usecond       924.66
    Elapsed Cycles                  cycle    1,888,835
    Memory Throughput                   %        10.93
    DRAM Throughput                     %         3.01
    Duration                      msecond         2.02
    L1/TEX Cache Throughput             %        71.75
    L2 Cache Throughput                 %        10.93
    SM Active Cycles                cycle   248,328.43
    Compute (SM) Throughput             %         2.28
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.79
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.21%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 2 256 1024 1024 gpu
CLI arguments: block_x = 2, block_y = 256, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 16780 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.586772 seconds.
==PROF== Disconnected from process 16780
[16780] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.79
    SM Frequency            cycle/usecond       935.53
    Elapsed Cycles                  cycle    1,915,194
    Memory Throughput                   %        10.79
    DRAM Throughput                     %         2.98
    Duration                      msecond         2.02
    L1/TEX Cache Throughput             %        72.04
    L2 Cache Throughput                 %        10.79
    SM Active Cycles                cycle   247,565.60
    Compute (SM) Throughput             %         2.25
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.79
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.21%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 2 512 1024 1024 gpu
CLI arguments: block_x = 2, block_y = 512, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 16830 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.564838 seconds.
==PROF== Disconnected from process 16830
[16830] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.78
    SM Frequency            cycle/usecond       933.48
    Elapsed Cycles                  cycle    1,913,680
    Memory Throughput                   %        10.76
    DRAM Throughput                     %         2.98
    Duration                      msecond         2.03
    L1/TEX Cache Throughput             %        72.60
    L2 Cache Throughput                 %        10.76
    SM Active Cycles                cycle   246,193.20
    Compute (SM) Throughput             %         2.26
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.81
    Achieved Active Warps Per SM           warp         7.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.19%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 4 1 1024 1024 gpu
CLI arguments: block_x = 4, block_y = 1, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 16910 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.62464 seconds.
==PROF== Disconnected from process 16910
[16910] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.63
    SM Frequency            cycle/usecond       913.12
    Elapsed Cycles                  cycle    1,886,936
    Memory Throughput                   %        10.96
    DRAM Throughput                     %         3.02
    Duration                      msecond         2.04
    L1/TEX Cache Throughput             %        72.03
    L2 Cache Throughput                 %        10.96
    SM Active Cycles                cycle   247,909.13
    Compute (SM) Throughput             %         2.29
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.79
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.21%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 4 2 1024 1024 gpu
CLI arguments: block_x = 4, block_y = 2, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 16975 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.583012 seconds.
==PROF== Disconnected from process 16975
[16975] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.64
    SM Frequency            cycle/usecond       914.32
    Elapsed Cycles                  cycle    1,859,380
    Memory Throughput                   %        11.10
    DRAM Throughput                     %         3.06
    Duration                      msecond         2.01
    L1/TEX Cache Throughput             %        72.81
    L2 Cache Throughput                 %        11.10
    SM Active Cycles                cycle   245,296.07
    Compute (SM) Throughput             %         2.32
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.82
    Achieved Active Warps Per SM           warp         7.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.18%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 4 4 1024 1024 gpu
CLI arguments: block_x = 4, block_y = 4, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 17035 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.544523 seconds.
==PROF== Disconnected from process 17035
[17035] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.68
    SM Frequency            cycle/usecond       919.83
    Elapsed Cycles                  cycle    1,881,391
    Memory Throughput                   %        10.97
    DRAM Throughput                     %         3.03
    Duration                      msecond         2.02
    L1/TEX Cache Throughput             %        72.18
    L2 Cache Throughput                 %        10.97
    SM Active Cycles                cycle      247,301
    Compute (SM) Throughput             %         2.29
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.77
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.23%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 4 8 1024 1024 gpu
CLI arguments: block_x = 4, block_y = 8, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 17092 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.514087 seconds.
==PROF== Disconnected from process 17092
[17092] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.76
    SM Frequency            cycle/usecond       930.54
    Elapsed Cycles                  cycle    1,879,103
    Memory Throughput                   %        10.98
    DRAM Throughput                     %         3.04
    Duration                      msecond         2.00
    L1/TEX Cache Throughput             %        72.31
    L2 Cache Throughput                 %        10.98
    SM Active Cycles                cycle   246,624.60
    Compute (SM) Throughput             %         2.29
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.78
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.22%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 4 16 1024 1024 gpu
CLI arguments: block_x = 4, block_y = 16, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 17139 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.533776 seconds.
==PROF== Disconnected from process 17139
[17139] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.75
    SM Frequency            cycle/usecond       929.61
    Elapsed Cycles                  cycle    1,911,455
    Memory Throughput                   %        10.82
    DRAM Throughput                     %         2.99
    Duration                      msecond         2.03
    L1/TEX Cache Throughput             %        71.60
    L2 Cache Throughput                 %        10.82
    SM Active Cycles                cycle   249,330.20
    Compute (SM) Throughput             %         2.26
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.79
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.21%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 4 32 1024 1024 gpu
CLI arguments: block_x = 4, block_y = 32, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 17192 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.531012 seconds.
==PROF== Disconnected from process 17192
[17192] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.66
    SM Frequency            cycle/usecond       918.10
    Elapsed Cycles                  cycle    1,865,457
    Memory Throughput                   %        11.08
    DRAM Throughput                     %         3.06
    Duration                      msecond         2.01
    L1/TEX Cache Throughput             %        72.24
    L2 Cache Throughput                 %        11.08
    SM Active Cycles                cycle   246,532.10
    Compute (SM) Throughput             %         2.32
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.80
    Achieved Active Warps Per SM           warp         7.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.2%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 4 64 1024 1024 gpu
CLI arguments: block_x = 4, block_y = 64, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 17239 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.514092 seconds.
==PROF== Disconnected from process 17239
[17239] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.72
    SM Frequency            cycle/usecond       925.81
    Elapsed Cycles                  cycle    1,885,643
    Memory Throughput                   %        10.98
    DRAM Throughput                     %         3.04
    Duration                      msecond         2.01
    L1/TEX Cache Throughput             %        72.69
    L2 Cache Throughput                 %        10.98
    SM Active Cycles                cycle   245,682.10
    Compute (SM) Throughput             %         2.29
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.80
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.2%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 4 128 1024 1024 gpu
CLI arguments: block_x = 4, block_y = 128, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 17319 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.530177 seconds.
==PROF== Disconnected from process 17319
[17319] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.72
    SM Frequency            cycle/usecond       924.18
    Elapsed Cycles                  cycle    1,875,553
    Memory Throughput                   %        10.98
    DRAM Throughput                     %         3.03
    Duration                      msecond         2.01
    L1/TEX Cache Throughput             %        73.00
    L2 Cache Throughput                 %        10.98
    SM Active Cycles                cycle   244,757.53
    Compute (SM) Throughput             %         2.30
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.82
    Achieved Active Warps Per SM           warp         7.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.18%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 4 256 1024 1024 gpu
CLI arguments: block_x = 4, block_y = 256, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 17393 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.548761 seconds.
==PROF== Disconnected from process 17393
[17393] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.82
    SM Frequency            cycle/usecond       939.69
    Elapsed Cycles                  cycle    1,894,196
    Memory Throughput                   %        10.88
    DRAM Throughput                     %         3.02
    Duration                      msecond         1.99
    L1/TEX Cache Throughput             %        72.27
    L2 Cache Throughput                 %        10.88
    SM Active Cycles                cycle   246,973.97
    Compute (SM) Throughput             %         2.28
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.77
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.23%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 8 1 1024 1024 gpu
CLI arguments: block_x = 8, block_y = 1, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 17457 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.617251 seconds.
==PROF== Disconnected from process 17457
[17457] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.84
    SM Frequency            cycle/usecond       942.82
    Elapsed Cycles                  cycle    1,909,117
    Memory Throughput                   %        10.83
    DRAM Throughput                     %         2.99
    Duration                      msecond         2.00
    L1/TEX Cache Throughput             %        72.93
    L2 Cache Throughput                 %        10.83
    SM Active Cycles                cycle   244,893.17
    Compute (SM) Throughput             %         2.26
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.80
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.2%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 8 2 1024 1024 gpu
CLI arguments: block_x = 8, block_y = 2, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 17507 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.536127 seconds.
==PROF== Disconnected from process 17507
[17507] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.65
    SM Frequency            cycle/usecond       916.00
    Elapsed Cycles                  cycle    1,892,357
    Memory Throughput                   %        10.93
    DRAM Throughput                     %         3.02
    Duration                      msecond         2.04
    L1/TEX Cache Throughput             %        72.42
    L2 Cache Throughput                 %        10.93
    SM Active Cycles                cycle   246,386.37
    Compute (SM) Throughput             %         2.28
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.79
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.21%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 8 4 1024 1024 gpu
CLI arguments: block_x = 8, block_y = 4, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 17557 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.494232 seconds.
==PROF== Disconnected from process 17557
[17557] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.78
    SM Frequency            cycle/usecond       934.73
    Elapsed Cycles                  cycle    1,920,671
    Memory Throughput                   %        10.77
    DRAM Throughput                     %         2.97
    Duration                      msecond         2.03
    L1/TEX Cache Throughput             %        72.56
    L2 Cache Throughput                 %        10.77
    SM Active Cycles                cycle   245,929.10
    Compute (SM) Throughput             %         2.25
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.77
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.23%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 8 8 1024 1024 gpu
CLI arguments: block_x = 8, block_y = 8, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 17607 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.480742 seconds.
==PROF== Disconnected from process 17607
[17607] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.77
    SM Frequency            cycle/usecond       933.08
    Elapsed Cycles                  cycle    1,882,033
    Memory Throughput                   %        10.97
    DRAM Throughput                     %         3.03
    Duration                      msecond         1.99
    L1/TEX Cache Throughput             %        72.50
    L2 Cache Throughput                 %        10.97
    SM Active Cycles                cycle   246,440.40
    Compute (SM) Throughput             %         2.29
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.81
    Achieved Active Warps Per SM           warp         7.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.19%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 8 16 1024 1024 gpu
CLI arguments: block_x = 8, block_y = 16, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 17654 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.497681 seconds.
==PROF== Disconnected from process 17654
[17654] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.92
    SM Frequency            cycle/usecond       953.97
    Elapsed Cycles                  cycle    1,920,642
    Memory Throughput                   %        10.75
    DRAM Throughput                     %         2.98
    Duration                      msecond         1.99
    L1/TEX Cache Throughput             %        73.23
    L2 Cache Throughput                 %        10.75
    SM Active Cycles                cycle   243,777.23
    Compute (SM) Throughput             %         2.25
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.82
    Achieved Active Warps Per SM           warp         7.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.18%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 8 32 1024 1024 gpu
CLI arguments: block_x = 8, block_y = 32, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 17734 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.530105 seconds.
==PROF== Disconnected from process 17734
[17734] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.77
    SM Frequency            cycle/usecond       933.57
    Elapsed Cycles                  cycle    1,886,133
    Memory Throughput                   %        10.94
    DRAM Throughput                     %         3.03
    Duration                      msecond         1.99
    L1/TEX Cache Throughput             %        72.33
    L2 Cache Throughput                 %        10.94
    SM Active Cycles                cycle   246,932.77
    Compute (SM) Throughput             %         2.29
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.78
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.22%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 8 64 1024 1024 gpu
CLI arguments: block_x = 8, block_y = 64, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 17813 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.49913 seconds.
==PROF== Disconnected from process 17813
[17813] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.85
    SM Frequency            cycle/usecond       942.28
    Elapsed Cycles                  cycle    1,905,777
    Memory Throughput                   %        10.76
    DRAM Throughput                     %         2.99
    Duration                      msecond         2.00
    L1/TEX Cache Throughput             %        72.35
    L2 Cache Throughput                 %        10.76
    SM Active Cycles                cycle   246,955.50
    Compute (SM) Throughput             %         2.26
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.80
    Achieved Active Warps Per SM           warp         7.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.2%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 8 128 1024 1024 gpu
CLI arguments: block_x = 8, block_y = 128, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 17869 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.50614 seconds.
==PROF== Disconnected from process 17869
[17869] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.69
    SM Frequency            cycle/usecond       922.77
    Elapsed Cycles                  cycle    1,877,834
    Memory Throughput                   %        11.01
    DRAM Throughput                     %         3.04
    Duration                      msecond         2.01
    L1/TEX Cache Throughput             %        72.13
    L2 Cache Throughput                 %        11.01
    SM Active Cycles                cycle   247,215.87
    Compute (SM) Throughput             %         2.30
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.79
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.21%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 16 1 1024 1024 gpu
CLI arguments: block_x = 16, block_y = 1, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 17919 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.594911 seconds.
==PROF== Disconnected from process 17919
[17919] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.77
    SM Frequency            cycle/usecond       932.78
    Elapsed Cycles                  cycle    1,902,202
    Memory Throughput                   %        10.88
    DRAM Throughput                     %         3.01
    Duration                      msecond         2.01
    L1/TEX Cache Throughput             %        72.43
    L2 Cache Throughput                 %        10.88
    SM Active Cycles                cycle   246,513.83
    Compute (SM) Throughput             %         2.27
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.79
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.21%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 16 2 1024 1024 gpu
CLI arguments: block_x = 16, block_y = 2, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 17969 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.523888 seconds.
==PROF== Disconnected from process 17969
[17969] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.77
    SM Frequency            cycle/usecond       933.26
    Elapsed Cycles                  cycle    1,877,058
    Memory Throughput                   %        11.01
    DRAM Throughput                     %         3.04
    Duration                      msecond         1.99
    L1/TEX Cache Throughput             %        72.77
    L2 Cache Throughput                 %        11.01
    SM Active Cycles                cycle   245,713.50
    Compute (SM) Throughput             %         2.30
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.79
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.21%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 16 4 1024 1024 gpu
CLI arguments: block_x = 16, block_y = 4, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 18019 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.533836 seconds.
==PROF== Disconnected from process 18019
[18019] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.80
    SM Frequency            cycle/usecond       937.99
    Elapsed Cycles                  cycle    1,907,089
    Memory Throughput                   %        10.84
    DRAM Throughput                     %         3.00
    Duration                      msecond         2.01
    L1/TEX Cache Throughput             %        72.88
    L2 Cache Throughput                 %        10.84
    SM Active Cycles                cycle   244,621.87
    Compute (SM) Throughput             %         2.26
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.79
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.21%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 16 8 1024 1024 gpu
CLI arguments: block_x = 16, block_y = 8, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 18091 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.541743 seconds.
==PROF== Disconnected from process 18091
[18091] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.67
    SM Frequency            cycle/usecond       919.71
    Elapsed Cycles                  cycle    1,892,190
    Memory Throughput                   %        10.93
    DRAM Throughput                     %         3.02
    Duration                      msecond         2.03
    L1/TEX Cache Throughput             %        72.36
    L2 Cache Throughput                 %        10.93
    SM Active Cycles                cycle   246,678.17
    Compute (SM) Throughput             %         2.28
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.81
    Achieved Active Warps Per SM           warp         7.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.19%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 16 16 1024 1024 gpu
CLI arguments: block_x = 16, block_y = 16, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 18161 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.515464 seconds.
==PROF== Disconnected from process 18161
[18161] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.85
    SM Frequency            cycle/usecond       944.42
    Elapsed Cycles                  cycle    1,930,275
    Memory Throughput                   %        10.69
    DRAM Throughput                     %         2.97
    Duration                      msecond         2.02
    L1/TEX Cache Throughput             %        72.48
    L2 Cache Throughput                 %        10.69
    SM Active Cycles                cycle   246,345.50
    Compute (SM) Throughput             %         2.24
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.80
    Achieved Active Warps Per SM           warp         7.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.2%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 16 32 1024 1024 gpu
CLI arguments: block_x = 16, block_y = 32, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 18242 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.504452 seconds.
==PROF== Disconnected from process 18242
[18242] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.75
    SM Frequency            cycle/usecond       931.66
    Elapsed Cycles                  cycle    1,924,914
    Memory Throughput                   %        10.76
    DRAM Throughput                     %         2.97
    Duration                      msecond         2.04
    L1/TEX Cache Throughput             %        72.80
    L2 Cache Throughput                 %        10.76
    SM Active Cycles                cycle   245,410.10
    Compute (SM) Throughput             %         2.25
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.78
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.22%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 16 64 1024 1024 gpu
CLI arguments: block_x = 16, block_y = 64, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 18298 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.528824 seconds.
==PROF== Disconnected from process 18298
[18298] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.75
    SM Frequency            cycle/usecond       928.43
    Elapsed Cycles                  cycle    1,877,098
    Memory Throughput                   %        10.98
    DRAM Throughput                     %         3.03
    Duration                      msecond         2.00
    L1/TEX Cache Throughput             %        72.45
    L2 Cache Throughput                 %        10.98
    SM Active Cycles                cycle   246,343.27
    Compute (SM) Throughput             %         2.30
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.78
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.22%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 32 1 1024 1024 gpu
CLI arguments: block_x = 32, block_y = 1, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 18348 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.568205 seconds.
==PROF== Disconnected from process 18348
[18348] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.68
    SM Frequency            cycle/usecond       920.15
    Elapsed Cycles                  cycle    1,894,371
    Memory Throughput                   %        10.88
    DRAM Throughput                     %         3.01
    Duration                      msecond         2.03
    L1/TEX Cache Throughput             %        72.38
    L2 Cache Throughput                 %        10.88
    SM Active Cycles                cycle   246,237.43
    Compute (SM) Throughput             %         2.28
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.79
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.21%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 32 2 1024 1024 gpu
CLI arguments: block_x = 32, block_y = 2, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 18398 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.596637 seconds.
==PROF== Disconnected from process 18398
[18398] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.71
    SM Frequency            cycle/usecond       924.44
    Elapsed Cycles                  cycle    1,909,038
    Memory Throughput                   %        10.83
    DRAM Throughput                     %         3.00
    Duration                      msecond         2.04
    L1/TEX Cache Throughput             %        72.25
    L2 Cache Throughput                 %        10.83
    SM Active Cycles                cycle   247,131.50
    Compute (SM) Throughput             %         2.26
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.78
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.22%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 32 4 1024 1024 gpu
CLI arguments: block_x = 32, block_y = 4, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 18448 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.539728 seconds.
==PROF== Disconnected from process 18448
[18448] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.67
    SM Frequency            cycle/usecond       918.62
    Elapsed Cycles                  cycle    1,892,479
    Memory Throughput                   %        10.90
    DRAM Throughput                     %         3.01
    Duration                      msecond         2.04
    L1/TEX Cache Throughput             %        72.47
    L2 Cache Throughput                 %        10.90
    SM Active Cycles                cycle   245,936.07
    Compute (SM) Throughput             %         2.28
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.78
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.22%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 32 8 1024 1024 gpu
CLI arguments: block_x = 32, block_y = 8, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 18531 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.518141 seconds.
==PROF== Disconnected from process 18531
[18531] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.85
    SM Frequency            cycle/usecond       943.65
    Elapsed Cycles                  cycle    1,915,701
    Memory Throughput                   %        10.82
    DRAM Throughput                     %         2.99
    Duration                      msecond         2.00
    L1/TEX Cache Throughput             %        72.78
    L2 Cache Throughput                 %        10.82
    SM Active Cycles                cycle   245,466.97
    Compute (SM) Throughput             %         2.25
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.80
    Achieved Active Warps Per SM           warp         7.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.2%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 32 16 1024 1024 gpu
CLI arguments: block_x = 32, block_y = 16, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 18595 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.560106 seconds.
==PROF== Disconnected from process 18595
[18595] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.67
    SM Frequency            cycle/usecond       918.53
    Elapsed Cycles                  cycle    1,870,884
    Memory Throughput                   %        11.04
    DRAM Throughput                     %         3.06
    Duration                      msecond         2.01
    L1/TEX Cache Throughput             %        72.35
    L2 Cache Throughput                 %        11.04
    SM Active Cycles                cycle      246,882
    Compute (SM) Throughput             %         2.31
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.80
    Achieved Active Warps Per SM           warp         7.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.2%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 32 32 1024 1024 gpu
CLI arguments: block_x = 32, block_y = 32, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 18655 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.534522 seconds.
==PROF== Disconnected from process 18655
[18655] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.88
    SM Frequency            cycle/usecond       948.19
    Elapsed Cycles                  cycle    1,935,950
    Memory Throughput                   %        10.69
    DRAM Throughput                     %         2.95
    Duration                      msecond         2.01
    L1/TEX Cache Throughput             %        72.06
    L2 Cache Throughput                 %        10.69
    SM Active Cycles                cycle   247,597.60
    Compute (SM) Throughput             %         2.23
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.77
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.23%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 64 1 1024 1024 gpu
CLI arguments: block_x = 64, block_y = 1, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 18712 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.526262 seconds.
==PROF== Disconnected from process 18712
[18712] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.63
    SM Frequency            cycle/usecond       914.67
    Elapsed Cycles                  cycle    1,885,935
    Memory Throughput                   %        10.97
    DRAM Throughput                     %         3.04
    Duration                      msecond         2.03
    L1/TEX Cache Throughput             %        72.31
    L2 Cache Throughput                 %        10.97
    SM Active Cycles                cycle   246,906.73
    Compute (SM) Throughput             %         2.29
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.79
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.21%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 64 2 1024 1024 gpu
CLI arguments: block_x = 64, block_y = 2, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 18762 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.52801 seconds.
==PROF== Disconnected from process 18762
[18762] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.79
    SM Frequency            cycle/usecond       934.11
    Elapsed Cycles                  cycle    1,917,892
    Memory Throughput                   %        10.78
    DRAM Throughput                     %         2.97
    Duration                      msecond         2.03
    L1/TEX Cache Throughput             %        72.89
    L2 Cache Throughput                 %        10.78
    SM Active Cycles                cycle   244,600.53
    Compute (SM) Throughput             %         2.25
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.80
    Achieved Active Warps Per SM           warp         7.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.2%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 64 4 1024 1024 gpu
CLI arguments: block_x = 64, block_y = 4, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 18812 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.547809 seconds.
==PROF== Disconnected from process 18812
[18812] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.74
    SM Frequency            cycle/usecond       929.10
    Elapsed Cycles                  cycle    1,913,612
    Memory Throughput                   %        10.80
    DRAM Throughput                     %         2.99
    Duration                      msecond         2.03
    L1/TEX Cache Throughput             %        71.62
    L2 Cache Throughput                 %        10.80
    SM Active Cycles                cycle   248,999.97
    Compute (SM) Throughput             %         2.26
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.81
    Achieved Active Warps Per SM           warp         7.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.19%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 64 8 1024 1024 gpu
CLI arguments: block_x = 64, block_y = 8, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 18862 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.540458 seconds.
==PROF== Disconnected from process 18862
[18862] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.59
    SM Frequency            cycle/usecond       908.15
    Elapsed Cycles                  cycle    1,873,849
    Memory Throughput                   %        11.03
    DRAM Throughput                     %         3.04
    Duration                      msecond         2.04
    L1/TEX Cache Throughput             %        72.61
    L2 Cache Throughput                 %        11.03
    SM Active Cycles                cycle   245,976.77
    Compute (SM) Throughput             %         2.30
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.82
    Achieved Active Warps Per SM           warp         7.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.18%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 64 16 1024 1024 gpu
CLI arguments: block_x = 64, block_y = 16, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 18942 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.554234 seconds.
==PROF== Disconnected from process 18942
[18942] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.60
    SM Frequency            cycle/usecond       909.05
    Elapsed Cycles                  cycle    1,874,389
    Memory Throughput                   %        11.03
    DRAM Throughput                     %         3.04
    Duration                      msecond         2.04
    L1/TEX Cache Throughput             %        72.23
    L2 Cache Throughput                 %        11.03
    SM Active Cycles                cycle   246,780.07
    Compute (SM) Throughput             %         2.30
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.78
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.22%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 128 1 1024 1024 gpu
CLI arguments: block_x = 128, block_y = 1, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 19024 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.548615 seconds.
==PROF== Disconnected from process 19024
[19024] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.75
    SM Frequency            cycle/usecond       930.58
    Elapsed Cycles                  cycle    1,894,821
    Memory Throughput                   %        10.90
    DRAM Throughput                     %         3.01
    Duration                      msecond         2.01
    L1/TEX Cache Throughput             %        72.36
    L2 Cache Throughput                 %        10.90
    SM Active Cycles                cycle   246,738.13
    Compute (SM) Throughput             %         2.28
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.80
    Achieved Active Warps Per SM           warp         7.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.2%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 128 2 1024 1024 gpu
CLI arguments: block_x = 128, block_y = 2, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 19083 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.54214 seconds.
==PROF== Disconnected from process 19083
[19083] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.69
    SM Frequency            cycle/usecond       923.48
    Elapsed Cycles                  cycle    1,899,261
    Memory Throughput                   %        10.92
    DRAM Throughput                     %         3.02
    Duration                      msecond         2.03
    L1/TEX Cache Throughput             %        72.37
    L2 Cache Throughput                 %        10.92
    SM Active Cycles                cycle   247,102.83
    Compute (SM) Throughput             %         2.28
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.79
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.21%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 128 4 1024 1024 gpu
CLI arguments: block_x = 128, block_y = 4, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 19133 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.576413 seconds.
==PROF== Disconnected from process 19133
[19133] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.76
    SM Frequency            cycle/usecond       931.46
    Elapsed Cycles                  cycle    1,908,153
    Memory Throughput                   %        10.84
    DRAM Throughput                     %         3.00
    Duration                      msecond         2.02
    L1/TEX Cache Throughput             %        71.93
    L2 Cache Throughput                 %        10.84
    SM Active Cycles                cycle   247,991.20
    Compute (SM) Throughput             %         2.26
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.76
    Achieved Active Warps Per SM           warp         7.92
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.24%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 128 8 1024 1024 gpu
CLI arguments: block_x = 128, block_y = 8, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 19183 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.551396 seconds.
==PROF== Disconnected from process 19183
[19183] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.75
    SM Frequency            cycle/usecond       930.06
    Elapsed Cycles                  cycle    1,915,031
    Memory Throughput                   %        10.79
    DRAM Throughput                     %         2.99
    Duration                      msecond         2.03
    L1/TEX Cache Throughput             %        72.72
    L2 Cache Throughput                 %        10.79
    SM Active Cycles                cycle   245,644.47
    Compute (SM) Throughput             %         2.25
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.81
    Achieved Active Warps Per SM           warp         7.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.19%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 256 1 1024 1024 gpu
CLI arguments: block_x = 256, block_y = 1, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 19233 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.545692 seconds.
==PROF== Disconnected from process 19233
[19233] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.69
    SM Frequency            cycle/usecond       922.05
    Elapsed Cycles                  cycle    1,887,545
    Memory Throughput                   %        10.98
    DRAM Throughput                     %         3.03
    Duration                      msecond         2.02
    L1/TEX Cache Throughput             %        72.21
    L2 Cache Throughput                 %        10.98
    SM Active Cycles                cycle   247,319.23
    Compute (SM) Throughput             %         2.29
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.78
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.22%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 256 2 1024 1024 gpu
CLI arguments: block_x = 256, block_y = 2, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 19293 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.550581 seconds.
==PROF== Disconnected from process 19293
[19293] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.88
    SM Frequency            cycle/usecond       948.13
    Elapsed Cycles                  cycle    1,907,692
    Memory Throughput                   %        10.83
    DRAM Throughput                     %         2.99
    Duration                      msecond         1.99
    L1/TEX Cache Throughput             %        72.37
    L2 Cache Throughput                 %        10.83
    SM Active Cycles                cycle   246,624.73
    Compute (SM) Throughput             %         2.26
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.81
    Achieved Active Warps Per SM           warp         7.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.19%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 256 4 1024 1024 gpu
CLI arguments: block_x = 256, block_y = 4, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 19363 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.546224 seconds.
==PROF== Disconnected from process 19363
[19363] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.83
    SM Frequency            cycle/usecond       940.99
    Elapsed Cycles                  cycle    1,910,275
    Memory Throughput                   %        10.83
    DRAM Throughput                     %         3.00
    Duration                      msecond         2.01
    L1/TEX Cache Throughput             %        72.62
    L2 Cache Throughput                 %        10.83
    SM Active Cycles                cycle   245,694.97
    Compute (SM) Throughput             %         2.26
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.80
    Achieved Active Warps Per SM           warp         7.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.2%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 512 1 1024 1024 gpu
CLI arguments: block_x = 512, block_y = 1, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 19444 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.55581 seconds.
==PROF== Disconnected from process 19444
[19444] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.63
    SM Frequency            cycle/usecond       913.48
    Elapsed Cycles                  cycle    1,885,498
    Memory Throughput                   %        10.97
    DRAM Throughput                     %         3.02
    Duration                      msecond         2.04
    L1/TEX Cache Throughput             %        72.53
    L2 Cache Throughput                 %        10.97
    SM Active Cycles                cycle   246,231.63
    Compute (SM) Throughput             %         2.29
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.79
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.21%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 512 2 1024 1024 gpu
CLI arguments: block_x = 512, block_y = 2, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 19503 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.566586 seconds.
==PROF== Disconnected from process 19503
[19503] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.77
    SM Frequency            cycle/usecond       932.86
    Elapsed Cycles                  cycle    1,892,364
    Memory Throughput                   %        10.92
    DRAM Throughput                     %         3.02
    Duration                      msecond         2.00
    L1/TEX Cache Throughput             %        72.36
    L2 Cache Throughput                 %        10.92
    SM Active Cycles                cycle   246,585.90
    Compute (SM) Throughput             %         2.28
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.81
    Achieved Active Warps Per SM           warp         7.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.19%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
Running Nsight Compute for kernel: softmax_attention_scores in directory: ./attention/build with args: 1024 1 1024 1024 gpu
CLI arguments: block_x = 1024, block_y = 1, M = 1024, N = 1024, mode = gpu
Input shape: [1024, 1024]
Output shape: [1024, 1024]
Running GPU forward pass...
==PROF== Connected to process 19553 (/home/tesla/exp/Notes/Cuda_kernels/attention/build/attention_solver)
==PROF== Profiling "softmax_attention_scores": 0%....50%....100% - 8 passes
GPU forward pass took 0.580378 seconds.
==PROF== Disconnected from process 19553
[19553] attention_solver@127.0.0.1
  softmax_attention_scores(float *, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         6.70
    SM Frequency            cycle/usecond       923.63
    Elapsed Cycles                  cycle    1,894,777
    Memory Throughput                   %        10.92
    DRAM Throughput                     %         3.03
    Duration                      msecond         2.02
    L1/TEX Cache Throughput             %        72.45
    L2 Cache Throughput                 %        10.92
    SM Active Cycles                cycle   246,322.67
    Compute (SM) Throughput             %         2.28
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              41
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block        byte/block               0
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.03
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 86.67%                                                                                          
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 30              
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.80
    Achieved Active Warps Per SM           warp         7.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 75.2%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (24.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

====================================================================================================
