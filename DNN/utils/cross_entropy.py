import numpy as np

MAX_ENTROPY = 1

def cross_entropy(predictions=None, ground_truth=None):
    """
    The function calculates the cross-entropy between predicted and ground truth values.
    
    :param predictions: The `predictions` parameter in the `cross_entropy` function represents the
    predicted values generated by a model. These values are typically probabilities assigned to
    different classes or outcomes. The function calculates the cross-entropy between these predicted
    values and the ground truth values
    :param ground_truth: The `ground_truth` parameter in the `cross_entropy` function represents the
    true labels or actual values that you are trying to predict. It is typically a 2D array where each
    row corresponds to a sample and each column corresponds to a class or category. The values in the
    `ground_truth`
    :return: the cross-entropy value calculated based on the predictions and ground truth provided.
    """
    if predictions is None or ground_truth is None:
        raise Exception("Error! Both predictions and ground truth must be float32 arrays")

    p = np.array(predictions).copy()
    y = np.array(ground_truth).copy()

    if p.shape != y.shape:
        raise Exception("Error! Both predictions and ground_truth must have same shape.")

    if len(p.shape) != 2:
        raise Exception("Error! Both predictions and ground_truth must be 2D arrays.")

    total_entropy = 0

    for i in range(p.shape[0]):
        for j in range(p.shape[1]):
            if y[i, j] == 1:
                total_entropy += min(np.abs(np.nan_to_num(np.log(p[i, j]))), MAX_ENTROPY)
            else:
                total_entropy += min(np.abs(np.nan_to_num(np.log(1 - p[i, j]))), MAX_ENTROPY)

    return total_entropy / p.size